{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFaSyxwHvKRc"
   },
   "source": [
    "# I. Set ups for Data\n",
    "- Create data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xurTLQvkvTYW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f61fc12d990>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "#device agnostic\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#Hyper Parameters\n",
    "RAND_SEED = 420\n",
    "torch.manual_seed(RAND_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLs_tsjKv3I2"
   },
   "source": [
    "## 1. Data Handling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd6yws-Av7Js"
   },
   "source": [
    "### 1.1 Set up for data handling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIjVX1DLwKFo",
    "outputId": "e898e1c5-62e8-44c6-b3bb-c76d99ba7442"
   },
   "outputs": [],
   "source": [
    "#Data paths\n",
    "data_folder_path = Path(\"../dataset\")\n",
    "data_path = data_folder_path / \"cfd_bench/cylinder\"\n",
    "bc_path = data_path / \"bc\"\n",
    "geo_path = data_path / \"geo\"\n",
    "prop_path = data_path / \"prop\"\n",
    "\n",
    "CHANNELS =2 #(vx,vy)\n",
    "GRID_SIZE =64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Compute  u and v attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_global_stats(data_dir):\n",
    "    \"\"\"\n",
    "    Computes global mean and std for u and v incrementally \n",
    "    to avoid Out-Of-Memory errors.\n",
    "    \"\"\"\n",
    "    print(f\"üîç Scanning {data_dir}...\")\n",
    "    \n",
    "    # 1. Get list of valid case directories\n",
    "    file_paths = sorted([\n",
    "        os.path.join(data_dir, f) for f in os.listdir(data_dir) \n",
    "        if os.path.isdir(os.path.join(data_dir, f))\n",
    "    ])\n",
    "    \n",
    "    if not file_paths:\n",
    "        print(\"‚ùå No data found.\")\n",
    "        return None\n",
    "\n",
    "    # 2. Initialize accumulators\n",
    "    # We use float64 to prevent overflow during accumulation\n",
    "    u_sum = 0.0\n",
    "    u_sq_sum = 0.0\n",
    "    v_sum = 0.0\n",
    "    v_sq_sum = 0.0\n",
    "    total_elements = 0\n",
    "\n",
    "    print(f\"üöÄ Computing stats over {len(file_paths)} simulation files...\")\n",
    "\n",
    "    # 3. Iterate file by file (Incremental Pass)\n",
    "    for case_path in tqdm(file_paths):\n",
    "        u_path = os.path.join(case_path, \"u.npy\")\n",
    "        v_path = os.path.join(case_path, \"v.npy\")\n",
    "        \n",
    "        # Handle potential missing files\n",
    "        if not os.path.exists(u_path) or not os.path.exists(v_path):\n",
    "            continue\n",
    "            \n",
    "        # Load one file into memory\n",
    "        # We don't strictly need mmap here since we process one by one, \n",
    "        # but it helps if individual files are massive.\n",
    "        u = np.load(u_path).astype(np.float64)\n",
    "        v = np.load(v_path).astype(np.float64)\n",
    "        \n",
    "        # Accumulate stats\n",
    "        # N = total pixels per file (Time * H * W)\n",
    "        n_pixels = u.size \n",
    "        total_elements += n_pixels\n",
    "        \n",
    "        u_sum += np.sum(u)\n",
    "        u_sq_sum += np.sum(u ** 2)\n",
    "        \n",
    "        v_sum += np.sum(v)\n",
    "        v_sq_sum += np.sum(v ** 2)\n",
    "\n",
    "    # 4. Final Calculation\n",
    "    # Mean = Sum / N\n",
    "    u_mean = u_sum / total_elements\n",
    "    v_mean = v_sum / total_elements\n",
    "    \n",
    "    # Std = sqrt( E[X^2] - (E[X])^2 )\n",
    "    # Variance = (Sum_Sq / N) - (Mean^2)\n",
    "    u_var = (u_sq_sum / total_elements) - (u_mean ** 2)\n",
    "    v_var = (v_sq_sum / total_elements) - (v_mean ** 2)\n",
    "    \n",
    "    u_std = np.sqrt(u_var)\n",
    "    v_std = np.sqrt(v_var)\n",
    "\n",
    "    print(\"\\n‚úÖ Global Stats Computed:\")\n",
    "    print(f\"u_mean: {u_mean:.4f}, u_std: {u_std:.4f}\")\n",
    "    print(f\"v_mean: {v_mean:.4f}, v_std: {v_std:.4f}\")\n",
    "    \n",
    "    return u_mean, u_std, v_mean, v_std\n",
    "\n",
    "# Usage\n",
    "# stats = compute_global_stats(\"path/to/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning ../dataset/cfd_bench/cylinder/prop...\n",
      "üöÄ Computing stats over 116 simulation files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 116/116 [00:06<00:00, 18.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Global Stats Computed:\n",
      "u_mean: 0.9953, u_std: 0.3867\n",
      "v_mean: 0.9739, v_std: 0.4182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "u_mean,v_mean,u_std,v_std  = compute_global_stats(prop_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Datasets classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CylinderFlow_SlidingWindow class defined.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Constants\n",
    "GRID_SIZE = 64\n",
    "CHANNELS = 2  # u, v\n",
    "\n",
    "class CylinderFlow_SlidingWindow(Dataset):\n",
    "    \"\"\"\n",
    "    Sliding Window Dataset for CFDBench Cylinder Flow.\n",
    "    - Extracts ALL valid overlapping windows from the timeline.\n",
    "    - Drastically increases dataset size (Data Augmentation by Time-Shifting).\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths, u_mean, v_mean, u_std, v_std, t_in=10, t_out=5, stride=1):\n",
    "        \"\"\"\n",
    "        stride (int): How many steps to shift the window. \n",
    "                      stride=1 means maximum overlap (maximum data).\n",
    "                      stride=10 means no overlap (like your previous version).\n",
    "        \"\"\"\n",
    "        self.t_in = t_in\n",
    "        self.t_out = t_out\n",
    "        self.total_sequence_len = t_in + t_out \n",
    "        self.stride = stride\n",
    "        \n",
    "        # Normalization Stats\n",
    "        self.u_mean, self.v_mean = u_mean, v_mean\n",
    "        self.u_std, self.v_std = u_std, v_std\n",
    "        \n",
    "        self.file_paths = file_paths\n",
    "        if not self.file_paths:\n",
    "            raise ValueError(\"No file paths provided.\")\n",
    "\n",
    "        # 1. Inspect first case to calculate dataset size\n",
    "        first_case = self.file_paths[0]\n",
    "        self.ext = '.npy' if os.path.exists(os.path.join(first_case, 'u.npy')) else '.np'\n",
    "        \n",
    "        # Load shape just once to calculate indices\n",
    "        sample_u = np.load(os.path.join(first_case, f'u{self.ext}'), mmap_mode='r')\n",
    "        self.total_timesteps_per_sim = sample_u.shape[0] # e.g., 600\n",
    "        \n",
    "        # Calculate how many valid windows fit in one simulation\n",
    "        # Example: 600 steps, need 15 contiguous. Valid starts are 0 to 585.\n",
    "        # Formula: (Total - Sequence) // Stride + 1\n",
    "        self.windows_per_sim = (self.total_timesteps_per_sim - self.total_sequence_len) // self.stride + 1\n",
    "        \n",
    "        self.length = len(self.file_paths) * self.windows_per_sim\n",
    "        \n",
    "        # 2. Cache Physics Parameters (Optimization)\n",
    "        # This prevents opening JSON files 50,000 times per epoch\n",
    "        self.case_params = []\n",
    "        for path in self.file_paths:\n",
    "            self.case_params.append(self._load_params(path))\n",
    "            \n",
    "        print(f\"‚úÖ Sliding Window Dataset Ready:\")\n",
    "        print(f\"   - Files: {len(self.file_paths)}\")\n",
    "        print(f\"   - Windows per file: {self.windows_per_sim} (Stride={stride})\")\n",
    "        print(f\"   - Total Samples: {self.length}\")\n",
    "\n",
    "    def _load_params(self, case_path):\n",
    "        json_path = os.path.join(case_path, \"params.json\")\n",
    "        if not os.path.exists(json_path):\n",
    "             json_path = os.path.join(case_path, \"case.json\")\n",
    "        \n",
    "        # Defaults\n",
    "        params = {\"viscosity\": 0.001, \"density\": 1.0, \"x_max\": 0.16, \"x_min\": -0.06, \"y_max\": 0.06, \"y_min\": -0.06}\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, \"r\") as f:\n",
    "                params.update(json.load(f))\n",
    "        return params\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Map global index to (Simulation Index, Window Index)\n",
    "        sim_idx = idx // self.windows_per_sim\n",
    "        window_idx = idx % self.windows_per_sim\n",
    "        \n",
    "        case_path = self.file_paths[sim_idx]\n",
    "        params_map = self.case_params[sim_idx] # Use cached params\n",
    "        \n",
    "        # 2. Calculate Time Indices\n",
    "        start_time = window_idx * self.stride\n",
    "        end_in = start_time + self.t_in\n",
    "        end_out = end_in + self.t_out\n",
    "\n",
    "        # 3. Load Data (mmap is fast for slicing)\n",
    "        u_mmap = np.load(os.path.join(case_path, f'u{self.ext}'), mmap_mode='r')\n",
    "        v_mmap = np.load(os.path.join(case_path, f'v{self.ext}'), mmap_mode='r')\n",
    "        \n",
    "        # 4. Slice\n",
    "        u_in = u_mmap[start_time : end_in]\n",
    "        v_in = v_mmap[start_time : end_in]\n",
    "        u_out = u_mmap[end_in : end_out]\n",
    "        v_out = v_mmap[end_in : end_out]\n",
    "\n",
    "        # 5. Normalize (On-the-fly)\n",
    "        u_in = (u_in - self.u_mean) / self.u_std        \n",
    "        v_in = (v_in - self.v_mean) / self.v_std        \n",
    "        u_out = (u_out - self.u_mean) / self.u_std        \n",
    "        v_out = (v_out - self.u_mean) / self.u_std        \n",
    "\n",
    "        # 6. Format to Tensor (C, H, W) for FNO\n",
    "        x_np = np.stack([u_in, v_in], axis=-1)\n",
    "        y_np = np.stack([u_out, v_out], axis=-1)\n",
    "        \n",
    "        # Permute: (Time, H, W, C) -> (H, W, Time*C)\n",
    "        # Note: Standard FNO usually takes (x, y, c), so we flatten time into channels\n",
    "        x_tensor = torch.from_numpy(x_np).permute(1, 2, 0, 3).reshape(GRID_SIZE, GRID_SIZE, -1)\n",
    "        y_tensor = torch.from_numpy(y_np).permute(1, 2, 0, 3).reshape(GRID_SIZE, GRID_SIZE, -1)\n",
    "        \n",
    "        return x_tensor.float(), y_tensor.float(), params_map\n",
    "\n",
    "print(\"‚úÖ CylinderFlow_SlidingWindow class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bxCbENcSXxn"
   },
   "source": [
    "# II. Set up for model\n",
    "- Declare up model class\n",
    "- Set up loss functions\n",
    "- Train - test function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvlONEUK9rrM"
   },
   "source": [
    "## 1.Models set ups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJtxm1_c9pux"
   },
   "source": [
    "### 1.1 FNO2D layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rwCocGjBmd-",
    "outputId": "45f5b864-143d-41c6-a79a-c73ec5b572b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNO_Layer2D class defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class FNO_Layer2D(nn.Module):\n",
    "  \"\"\" A class act as one Fourier Layer as described in the original paper\"\"\"\n",
    "  def __init__(self,in_chanels, out_chanels,mode_x,mode_y):\n",
    "    super(FNO_Layer2D, self).__init__()\n",
    "    self.in_chanels = in_chanels\n",
    "    self.out_chanels = out_chanels\n",
    "    self.mode_x = mode_x\n",
    "    self.mode_y = mode_y\n",
    "    #Scaler to scale the parameters\n",
    "    self.scalar = (1/(in_chanels * out_chanels))\n",
    "    self.weight_x = nn.Parameter(\n",
    "        self.scalar * torch.rand(in_chanels,out_chanels,mode_x, mode_y, dtype = torch.cfloat)\n",
    "    )\n",
    "    self.weight_y = nn.Parameter(\n",
    "        self.scalar * torch.rand(in_chanels,out_chanels,mode_x, mode_y,dtype = torch.cfloat)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    #Size \n",
    "    batch,_,H,W = x.shape\n",
    "      \n",
    "    # FFT (2D fourier transform)\n",
    "    x_ft = torch.fft.rfft2(x)\n",
    "      \n",
    "    ## Fourier layer\n",
    "    out_ft = torch.zeros(\n",
    "        batch, self.out_chanels,H, W //2 +1,\n",
    "        dtype = torch.cfloat,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "    out_ft[:,:,:self.mode_x,:self.mode_y] = torch.einsum(\n",
    "        \"bixy,ioxy->boxy\",\n",
    "        x_ft[:,:,:self.mode_x,:self.mode_y],\n",
    "        self.weight_x\n",
    "    )\n",
    "\n",
    "    out_ft[:,:,-self.mode_x:,:self.mode_y] = torch.einsum(\n",
    "        \"bixy,ioxy->boxy\",\n",
    "        x_ft[:,:,-self.mode_x:, :self.mode_y],\n",
    "        self.weight_y\n",
    "    )\n",
    "    ## Inverse FFT\n",
    "    x = torch.fft.irfft2(out_ft , s=(H,W))\n",
    "    return x\n",
    "print(\"FNO_Layer2D class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQ8niYFl9tQW"
   },
   "source": [
    "### 1.2 FNO2D class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zrdAHRpJHZ9c",
    "outputId": "fd2c80f3-ef01-4e53-fa5c-34e95a783416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNO2D class defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FNO2D(nn.Module):\n",
    "    def __init__(self, width, mode_x, mode_y, in_chanels=1, out_chanels=200):\n",
    "        \"\"\" Default is 1 time step -> 200 timestep rest\"\"\"\n",
    "        super(FNO2D, self).__init__()\n",
    "        self.in_chanels = in_chanels + 2 # add one more for the grid\n",
    "        self.out_chanels = out_chanels\n",
    "        self.width = width\n",
    "        self.mode_x = mode_x\n",
    "        self.mode_y = mode_y\n",
    "        \n",
    "        # P layer (lift the input channel up):\n",
    "        self.fc0 = nn.Linear(self.in_chanels, self.width)\n",
    "\n",
    "        # T block: 4 Fourier layers\n",
    "        self.conv0 = FNO_Layer2D(width, width, mode_x, mode_y)\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "\n",
    "        self.conv1 = FNO_Layer2D(width, width, mode_x, mode_y)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "\n",
    "        self.conv2 = FNO_Layer2D(width, width, mode_x, mode_y)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "\n",
    "        self.conv3 = FNO_Layer2D(width, width, mode_x, mode_y)\n",
    "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
    "\n",
    "        # Q layer (project down to output_chanels)\n",
    "        self.fc1 = nn.Linear(width, width * 2)\n",
    "        self.fc2 = nn.Linear(width * 2, self.out_chanels)\n",
    "\n",
    "    def forward(self, x, params_map=None):\n",
    "        # Get the grid information\n",
    "        # FIX: Removed syntax error (positional arg after keyword arg)\n",
    "        grid = get_grid(x.shape, params_map, x.device) \n",
    "\n",
    "        # concat to the input\n",
    "        x = torch.cat((x, grid), dim=-1) # (batch,H,W,chanels)\n",
    "\n",
    "        ## Through P layer:\n",
    "        x = self.fc0(x)\n",
    "\n",
    "        x = x.permute(0, 3, 1, 2) # (batch, chanel , H , W)\n",
    "\n",
    "        ## Through T\n",
    "        # 1\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        # 2\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        # 3\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        # 4\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        # Switch back\n",
    "        x = x.permute(0, 2, 3, 1) # (batch,H,W,chanels)\n",
    "\n",
    "        ## Through Q\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def get_grid(shape, params_map, device): \n",
    "    batch, H, W = shape[0], shape[1], shape[2]\n",
    "    \n",
    "    # --- ROBUST PARAMETER EXTRACTION ---\n",
    "    # The DataLoader returns Batched Tensors (e.g., size 32).\n",
    "    # We need scalars for linspace. We assume the domain is constant for the batch.\n",
    "    if params_map and 'x_min' in params_map:\n",
    "        # Take the first element and convert to python float\n",
    "        # This prevents \"RuntimeError: The truth value of an array...\"\n",
    "        x_min = params_map['x_min'][0].item() if torch.is_tensor(params_map['x_min']) else params_map['x_min']\n",
    "        x_max = params_map['x_max'][0].item() if torch.is_tensor(params_map['x_max']) else params_map['x_max']\n",
    "        y_min = params_map['y_min'][0].item() if torch.is_tensor(params_map['y_min']) else params_map['y_min']\n",
    "        y_max = params_map['y_max'][0].item() if torch.is_tensor(params_map['y_max']) else params_map['y_max']\n",
    "    else:\n",
    "        # Fallback defaults\n",
    "        x_min, x_max, y_min, y_max = -1.0, 1.0, -1.0, 1.0\n",
    "\n",
    "    # --- ASPECT RATIO PRESERVATION STRATEGY ---\n",
    "    # Raw coordinates (e.g., 0.16) are very small for neural networks.\n",
    "    # It is better to normalize the LONGEST dimension to [0, 1] \n",
    "    # and scale the other dimension to preserve aspect ratio.\n",
    "    \n",
    "    width_x = x_max - x_min\n",
    "    height_y = y_max - y_min\n",
    "    \n",
    "    # Prevent division by zero\n",
    "    if width_x == 0: width_x = 1.0\n",
    "    \n",
    "    aspect_ratio = height_y / width_x\n",
    "\n",
    "    # X goes from 0 to 1 (Normalized)\n",
    "    grid_x = torch.linspace(0, 1, H, device=device, dtype=torch.float)\n",
    "    # Y goes from 0 to aspect_ratio (e.g., 0.375)\n",
    "    grid_y = torch.linspace(0, aspect_ratio, W, device=device, dtype=torch.float)\n",
    "\n",
    "    # Reshape for broadcasting\n",
    "    grid_x = grid_x.view(1, H, 1, 1).expand(batch, -1, W, -1)\n",
    "    grid_y = grid_y.view(1, 1, W, 1).expand(batch, H, -1, -1)\n",
    "\n",
    "    # Concatenate\n",
    "    grid = torch.cat((grid_x, grid_y), dim=-1)\n",
    "    return grid \n",
    "\n",
    "print(\"FNO2D class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OESnYwx8-l3q"
   },
   "source": [
    "## 2.Loss functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Physic loss for NavierStoke2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hXTFStOJQYA_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NavierStoke2DLoss(nn.Module):\n",
    "    def __init__(self, dt=0.001, size_average=True,u_mean = u_mean , v_mean = v_mean , u_std = u_std, v_std =v_std):\n",
    "        super(NavierStoke2DLoss, self).__init__()\n",
    "        \n",
    "        self.dt = dt\n",
    "        self.u_mean = u_mean\n",
    "        self.v_mean = v_mean\n",
    "        self.u_std = u_std\n",
    "        self.v_std = v_std\n",
    "        \n",
    "        self.data_loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "        print(f\"üìâ Loss Initialized\")\n",
    "\n",
    "    def compute_derivatives(self, u, v):\n",
    "        \"\"\"\n",
    "        Vectorized derivatives for sequence (B, H, W, T)\n",
    "        Maintains (B, T, H, W) structure to allow broadcasting with (B) parameters.\n",
    "        \"\"\"\n",
    "        # Input shape: (B, H, W, T)\n",
    "        b, h, w, t = u.shape\n",
    "        \n",
    "        # Permute to (B, T, H, W) - DO NOT FLATTEN B and T\n",
    "        u_perm = u.permute(0, 3, 1, 2)\n",
    "        v_perm = v.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Pad spatial dims (H and W). F.pad works on the last dimensions.\n",
    "        # Padding (left, right, top, bottom)\n",
    "        u_pad = F.pad(u_perm, (1, 1, 1, 1), mode='replicate')\n",
    "        v_pad = F.pad(v_perm, (1, 1, 1, 1), mode='replicate')\n",
    "\n",
    "        # Reshape dx/dy for broadcasting: (B) -> (B, 1, 1, 1)\n",
    "        dx_view = self.dx.view(b, 1, 1, 1)\n",
    "        dy_view = self.dy.view(b, 1, 1, 1)\n",
    "\n",
    "        # Calculate Gradients. Result shape: (B, T, H, W)\n",
    "        du_dx = (u_pad[..., 1:-1, 2:] - u_pad[..., 1:-1, :-2]) / (2 * dx_view)\n",
    "        du_dy = (u_pad[..., 2:, 1:-1] - u_pad[..., :-2, 1:-1]) / (2 * dy_view)\n",
    "        dv_dx = (v_pad[..., 1:-1, 2:] - v_pad[..., 1:-1, :-2]) / (2 * dx_view)\n",
    "        dv_dy = (v_pad[..., 2:, 1:-1] - v_pad[..., :-2, 1:-1]) / (2 * dy_view)\n",
    "\n",
    "        # Reshape back to (B, H, W, T)\n",
    "        return (\n",
    "            du_dx.permute(0, 2, 3, 1),\n",
    "            dv_dx.permute(0, 2, 3, 1),\n",
    "            du_dy.permute(0, 2, 3, 1),\n",
    "            dv_dy.permute(0, 2, 3, 1)\n",
    "        )\n",
    "\n",
    "    def laplacian(self, w):\n",
    "        # Input w shape: (B, H, W, T)\n",
    "        b, h, w_dim, t = w.shape\n",
    "        \n",
    "        # Permute to (B, T, H, W)\n",
    "        w_perm = w.permute(0, 3, 1, 2)\n",
    "        w_pad = F.pad(w_perm, (1, 1, 1, 1), mode='replicate')\n",
    "        \n",
    "        # Reshape dx/dy for broadcasting: (B, 1, 1, 1)\n",
    "        dx_view = self.dx.view(b, 1, 1, 1)\n",
    "        dy_view = self.dy.view(b, 1, 1, 1)\n",
    "\n",
    "        d2x = (w_pad[..., 1:-1, 2:] - 2 * w_pad[..., 1:-1, 1:-1] + w_pad[..., 1:-1, :-2]) / (dx_view ** 2)\n",
    "        d2y = (w_pad[..., 2:, 1:-1] - 2 * w_pad[..., 1:-1, 1:-1] + w_pad[..., :-2, 1:-1]) / (dy_view ** 2)\n",
    "        \n",
    "        return (d2x + d2y).permute(0, 2, 3, 1)\n",
    "\n",
    "    def cal_physics_loss(self, u, v):\n",
    "        \"\"\"\n",
    "        u, v shape: (B, H, W, T_total)\n",
    "        \"\"\"\n",
    "        # 1. Get Viscosity (Batch, 1, 1, 1) for broadcasting against (B, H, W, T)\n",
    "        # Use a local variable to avoid modifying self.nu in place repeatedly\n",
    "        nu_view = self.nu.view(-1, 1, 1, 1)\n",
    "\n",
    "        # 2. Compute Derivatives\n",
    "        du_dx, dv_dx, du_dy, dv_dy = self.compute_derivatives(u, v)\n",
    "\n",
    "        # --- Continuity Loss ---\n",
    "        loss_con = torch.mean((du_dx + dv_dy) ** 2)\n",
    "\n",
    "        # --- Vorticity Loss ---\n",
    "        omega = dv_dx - du_dy\n",
    "        \n",
    "        # Time Derivative (Central Difference)\n",
    "        omega_next = omega[..., 2:]\n",
    "        omega_prev = omega[..., :-2]\n",
    "        dw_dt = (omega_next - omega_prev) / (2 * self.dt)\n",
    "        \n",
    "        # Align Spatial Terms (Slice to center to match time slicing)\n",
    "        u_center = u[..., 1:-1]\n",
    "        v_center = v[..., 1:-1]\n",
    "        omega_center = omega[..., 1:-1]\n",
    "        \n",
    "        # Advection terms (u * grad(w))\n",
    "        dw_dx, _, dw_dy, _ = self.compute_derivatives(omega_center, torch.zeros_like(omega_center))\n",
    "        advection = u_center * dw_dx + v_center * dw_dy\n",
    "        \n",
    "        # Diffusion term\n",
    "        diffusion = nu_view * self.laplacian(omega_center)\n",
    "        \n",
    "        # Residual\n",
    "        residual = dw_dt + advection - diffusion\n",
    "        loss_vort = torch.mean(residual ** 2)\n",
    "\n",
    "        return loss_vort, loss_con\n",
    "\n",
    "    def forward(self, x_in, y_pred, y_true, params_map):\n",
    "        \"\"\"\n",
    "        x_in: (Batch, H, W, 20 ) -> Contains History\n",
    "        y_pred: (Batch, H, W, T_out*2) -> Contains Predictions\n",
    "        \"\"\"\n",
    "        # 1. Setup Grid (Physical Units)\n",
    "        # Ensure these are on the correct device\n",
    "        x_max = params_map.get(\"x_max\", 1.0).to(y_pred.device)\n",
    "        x_min = params_map.get(\"x_min\", 0.0).to(y_pred.device)\n",
    "        y_max = params_map.get(\"y_max\", 1.0).to(y_pred.device)\n",
    "        y_min = params_map.get(\"y_min\", 0.0).to(y_pred.device)\n",
    "        \n",
    "        x_range = x_max - x_min\n",
    "        y_range = y_max - y_min\n",
    "        \n",
    "        self.nu = (params_map.get(\"viscosity\", 0.001)/ params_map.get(\"density\")).to(y_pred.device) # dataset give dynamic vis coe so we make it kinetic nu\n",
    "        self.dx = x_range / 64.0\n",
    "        self.dy = y_range / 64.0\n",
    "\n",
    "        # 2. Data Loss\n",
    "        data_loss = self.data_loss_fn(y_pred, y_true)\n",
    "\n",
    "        # 3. Stitch History + Prediction for Physics\n",
    "        x_last = x_in[...,-2:]\n",
    "        vel_traj = torch.cat((x_last, y_pred), dim=-1) \n",
    "        \n",
    "        # Unpack Prediction (Interleaved u, v)\n",
    "        b, h, w, c = vel_traj.shape\n",
    "        # Ensure steps are integer division\n",
    "        t_steps = c // 2\n",
    "        vel_traj = vel_traj.view(b, h, w, t_steps, 2)\n",
    "        u_full = vel_traj[..., 0]\n",
    "        v_full = vel_traj[..., 1]\n",
    "\n",
    "        #De-normalized\n",
    "        u_og = u_full * self.u_std + self.u_mean\n",
    "        v_og = v_full * self.v_std + self.v_mean\n",
    "       \n",
    "        # 4. Calculate Physics\n",
    "        loss_vort, loss_con = self.cal_physics_loss(u_og, v_og)\n",
    "\n",
    "        return data_loss, loss_vort, loss_con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Loss function for autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLossOnly(nn.Module):\n",
    "    def __init__(self,size_average = True):\n",
    "        super(DataLossOnly,self).__init__()\n",
    "        self.size_average = size_average \n",
    "        self.data_loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "        \n",
    "    def forward(self,y_pred,y_target): \n",
    "        data_loss = self.data_loss_fn(y_pred,y_target) \n",
    "        return data_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwrbOb0Im6_N"
   },
   "source": [
    "## 3 Training & Evaluating process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVCqCrmtnB6c"
   },
   "source": [
    "### 3.1 Training and testing loops + printing time method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UiPrn5AiItIY"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, data_loader, phys_weight, loss_fn, optimizer, device, noise_level, rollout_steps, sampling_prob):\n",
    "    model.train()\n",
    "    total_data_loss = 0.0\n",
    "    total_phys_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Weights for the two physics components\n",
    "    W_VORT = 1.0\n",
    "    W_CONT = 1.0\n",
    "    CHANNELS = 2\n",
    "\n",
    "    for x, y, params_map in data_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Noise injection for stability\n",
    "        if noise_level > 0.0:\n",
    "            x_noisy = x + torch.randn_like(x) * x.std() * noise_level\n",
    "            x_current = x_noisy\n",
    "        else:\n",
    "            x_current = x\n",
    "            \n",
    "        predictions = [] # List to store steps\n",
    "        \n",
    "        # --- ROLLOUT LOOP ---\n",
    "        for step in range(rollout_steps):\n",
    "            \n",
    "            # 1. Forward Pass\n",
    "            y_pred = model(x_current) # (B, H, W, 2)\n",
    "            predictions.append(y_pred) # Store it\n",
    "            \n",
    "            # 2. Prepare Input for NEXT step\n",
    "            start_c = step * CHANNELS\n",
    "            end_c = (step + 1) * CHANNELS\n",
    "            y_target_step = y[..., start_c:end_c]\n",
    "            \n",
    "            # 3. Update Window (Autoregressive Logic)\n",
    "            if torch.rand(1) < sampling_prob:\n",
    "                next_in = y_target_step # Teacher Forcing\n",
    "            else:\n",
    "                next_in = y_pred        # Autoregressive\n",
    "                \n",
    "            # Slide window: Drop first 2 channels, add new 2\n",
    "            x_current = torch.cat([\n",
    "                x_current[..., CHANNELS:], \n",
    "                next_in], dim=-1)\n",
    "\n",
    "        # --- END OF LOOP ---\n",
    "\n",
    "        # 4. Prepare Tensors for Loss\n",
    "        # Stack predictions along channel dim: (B, H, W, Rollout*2)\n",
    "        y_pred_full = torch.cat(predictions, dim=-1)\n",
    "        \n",
    "        # Slice ground truth to match rollout length\n",
    "        target_channels = rollout_steps * CHANNELS\n",
    "        y_target_full = y[..., :target_channels]\n",
    "\n",
    "        # 5. Calculate Loss ONCE on the full sequence\n",
    "        # Note: loss_fn expects (x_in, y_pred, y_target, params)\n",
    "        data_loss, vort_loss, con_loss = loss_fn(x, y_pred_full, y_target_full, params_map)\n",
    "        \n",
    "        # 6. Accumulate\n",
    "        phys_term = phys_weight * (W_VORT * vort_loss + W_CONT * con_loss)\n",
    "        loss_accumulated = data_loss + phys_term\n",
    "        \n",
    "        total_data_loss += data_loss.item()\n",
    "        total_phys_loss += phys_term.item() \n",
    "        total_samples += 1\n",
    "\n",
    "        # 7. Backward Pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_accumulated.backward()\n",
    "        \n",
    "        # Clip gradients (Essential for AR training)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "\n",
    "    return total_data_loss / total_samples, total_phys_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aMb5BiS5qdhL"
   },
   "outputs": [],
   "source": [
    "def testing_loop(model, data_loader, loss_fn, rollout_steps,device):\n",
    "    model.eval()\n",
    "    val_data_loss = 0\n",
    "    CHANNELS = 2\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for x_batch, y_batch, params_map in data_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            predictions =[]\n",
    "            x_current = x_batch\n",
    "            \n",
    "            for step in range(rollout_steps): \n",
    "                y_pred = model(x_current) # Output: (B, H, W, C)\n",
    "                predictions.append(y_pred)\n",
    "                x_current =torch.cat([x_current[...,CHANNELS:], y_pred],dim =-1)\n",
    "\n",
    "\n",
    "            # --- ROBUST LOSS CALCULATION ---\n",
    "            # DataLossOnly returns 1 value. Physics loss returns 3.\n",
    "            # We try to unpack; if it fails, we assume it's a single value.\n",
    "            y_pred_tensor = torch.cat(predictions, dim=-1) \n",
    "            loss_output = loss_fn(y_pred_tensor, y_batch[...,:CHANNELS*rollout_steps]) \n",
    "            \n",
    "            if isinstance(loss_output, tuple):\n",
    "                data_loss = loss_output[0] # Extract data loss from (data, vort, con)\n",
    "            else:\n",
    "                data_loss = loss_output    # It's just the scalar data loss\n",
    "\n",
    "            val_data_loss += data_loss.item()\n",
    "\n",
    "    return val_data_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TxQddBbytHSx"
   },
   "outputs": [],
   "source": [
    "def printing_time(start, end, model_name):\n",
    "    print(f\"It takes {(end-start):.2f} s to train {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dy8_8IFhyX8A"
   },
   "source": [
    "### 3.2 Traing & validating for epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nZ1R_mhfs4_1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def train_and_test(lr_scheduler, model, phys_loss, data_loss, optimizer, phys_weight, train_loader,\n",
    "                   dev_loader, epochs, device, noise_level, rollout_steps, sampling_prob):\n",
    "    model.to(device)\n",
    "    \n",
    "    # --- CONFIGURATION ---\n",
    "    WARMUP_EPOCHS = 5  \n",
    "    RAMP_EPOCHS = 10   # Epochs 5-14: Linearly increase weight\n",
    "    # ---------------------\n",
    "\n",
    "    results = {\"train_data_loss\": [], \"train_phys_loss\": [], \"val_data_loss\": []}\n",
    "    start_time = timer()\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        # --- 1. DYNAMIC WEIGHT SCHEDULE ---\n",
    "        if epoch < WARMUP_EPOCHS:\n",
    "            curr_phys_weight = 0.0\n",
    "            phase = \"Data Only\"\n",
    "        elif epoch < (WARMUP_EPOCHS + RAMP_EPOCHS):\n",
    "            # Linear ramp: 0.0 -> target_phys_weight\n",
    "            progress = (epoch - WARMUP_EPOCHS) / RAMP_EPOCHS\n",
    "            curr_phys_weight = phys_weight * progress\n",
    "            phase = f\"Ramping ({progress:.0%})\"\n",
    "        else:\n",
    "            curr_phys_weight = phys_weight\n",
    "            phase = \"Full Phys\"\n",
    "            \n",
    "        # --- 2. TEACHER FORCING DECAY ---\n",
    "        # Slowly reduce reliance on ground truth history\n",
    "        if epoch > 0 and epoch % 8 == 0:\n",
    "            sampling_prob = max(0.0, sampling_prob - 0.1)\n",
    "\n",
    "        # --- 3. TRAINING ---\n",
    "        train_data_loss, train_phys_loss = training_loop(\n",
    "            model, train_loader, curr_phys_weight, phys_loss, optimizer, \n",
    "            device, noise_level, rollout_steps, sampling_prob\n",
    "        )\n",
    "\n",
    "        # --- 4. VALIDATION ---\n",
    "        val_data_loss = testing_loop(model, dev_loader, data_loss, rollout_steps, device)\n",
    "        \n",
    "        # Update Scheduler based on Validation Data Loss\n",
    "        lr_scheduler.step(val_data_loss)\n",
    "\n",
    "        # --- 5. LOGGING ---\n",
    "        # We log the RAW physics loss to monitor the billions, \n",
    "        # but the training uses the 'curr_phys_weight' to keep gradients safe.\n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"[{epoch}/{epochs}] {phase} | Train Data Loss: {train_data_loss:.4e} | Train Phys Loss: {train_phys_loss:.2e} | Val: {val_data_loss:.4e}\")\n",
    "\n",
    "        results[\"train_data_loss\"].append(train_data_loss)\n",
    "        results[\"train_phys_loss\"].append(train_phys_loss)\n",
    "        results[\"val_data_loss\"].append(val_data_loss)\n",
    "\n",
    "    end_time = timer()\n",
    "    printing_time(start_time, end_time, type(model).__name__)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr18PLMh4_QT"
   },
   "source": [
    "### 3.3 Evaluating model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTXuX_L7-HcG"
   },
   "source": [
    "# III. Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vigQePZJFIG"
   },
   "source": [
    "## 1.DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 T10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Split: 92 Train, 11 Val, 13 Test files.\n",
      "‚úÖ Sliding Window Dataset Ready:\n",
      "   - Files: 92\n",
      "   - Windows per file: 165 (Stride=6)\n",
      "   - Total Samples: 15180\n",
      "‚úÖ Sliding Window Dataset Ready:\n",
      "   - Files: 11\n",
      "   - Windows per file: 66 (Stride=15)\n",
      "   - Total Samples: 726\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "T_IN =10\n",
    "T_OUT =5\n",
    "# 1. Get all available simulation paths\n",
    "all_files = sorted([\n",
    "    os.path.join(prop_path, f) for f in os.listdir(prop_path) \n",
    "    if os.path.isdir(os.path.join(prop_path, f))\n",
    "])\n",
    "\n",
    "# 2. Shuffle and Split Files (80% Train, 10% Val, 10% Test)\n",
    "# Set seed for reproducibility!\n",
    "random.seed(42) \n",
    "random.shuffle(all_files)\n",
    "\n",
    "n_total = len(all_files)\n",
    "n_train = int(0.8 * n_total)\n",
    "n_val = int(0.1 * n_total)\n",
    "\n",
    "train_files = all_files[:n_train]\n",
    "val_files   = all_files[n_train:n_train+n_val]\n",
    "test_files  = all_files[n_train+n_val:]\n",
    "\n",
    "print(f\"üìÇ Split: {len(train_files)} Train, {len(val_files)} Val, {len(test_files)} Test files.\")\n",
    "\n",
    "# 3. Instantiate Separate Datasets\n",
    "train_ds = CylinderFlow_SlidingWindow(\n",
    "    file_paths=train_files,\n",
    "    t_in=T_IN, \n",
    "    t_out=T_OUT, \n",
    "    stride = 6,\n",
    "    u_mean = u_mean,\n",
    "    v_mean = v_mean,\n",
    "    u_std = u_std,\n",
    "    v_std = v_std\n",
    ")\n",
    "\n",
    "val_ds = CylinderFlow_SlidingWindow(\n",
    "    file_paths=val_files,\n",
    "    t_in=T_IN, \n",
    "    t_out=T_OUT, \n",
    "    u_mean = u_mean,\n",
    "    v_mean = v_mean,\n",
    "    u_std = u_std,\n",
    "    v_std = v_std,\n",
    "    stride = T_IN + T_OUT,\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Create DataLoaders\n",
    "train_loader_t10 = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader_t10   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iEmNvrMskFm"
   },
   "source": [
    "## 4. Model 5\n",
    "**(Plautaue at .. epoch after .. hour)\n",
    "\n",
    "** Model 5 (Autoregressive, 3-in) Test Loss: \n",
    "\n",
    "- use data_t10 \n",
    "- FNO2D\n",
    "- NavierStoke2D loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPER Parameters from the paper\n",
    "WIDTH =64\n",
    "T_IN =10\n",
    "T_OUT =1\n",
    "MODE_X = 12\n",
    "MODE_Y = 12\n",
    "\n",
    "#Define model\n",
    "model5 = FNO2D(in_chanels=T_IN*CHANNELS, \n",
    "                 out_chanels=T_OUT*CHANNELS, \n",
    "                 mode_x=MODE_X, \n",
    "                 mode_y=MODE_Y, \n",
    "                 width=WIDTH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Loss Initialized\n"
     ]
    }
   ],
   "source": [
    "dt =0.001 #(Please modify if doesnt match)\n",
    "phys_loss_fn5 = NavierStoke2DLoss(dt = dt, size_average =True)\n",
    "data_loss_fn5 = DataLossOnly(size_average = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "#Optimizer (Adam)\n",
    "LR =0.001\n",
    "optimizer5 = torch.optim.Adam(model5.parameters(),lr = LR)\n",
    "\n",
    "# We'll use 'ReduceLROnPlateau'.\n",
    "# This scheduler will automatically \"reduce\" the learning rate\n",
    "# when it detects that our validation loss has \"plateaued\" (stopped improving).\n",
    "scheduler5 = ReduceLROnPlateau(\n",
    "    optimizer5,\n",
    "    mode='min',      # It will look at the validation loss, where 'min' is better\n",
    "    factor=0.1,      # Reduce LR by a factor of 10 (e.g., 0.001 -> 0.0001)\n",
    "    patience=5,      # Wait 5 epochs for improvement before reducing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training and testing model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b570260143475ba557711791000200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/32] Data Only | Train Data Loss: 3.3339e-03 | Train Phys Loss: 0.00e+00 | Val: 1.0168e-04\n",
      "[1/32] Data Only | Train Data Loss: 5.9073e-05 | Train Phys Loss: 0.00e+00 | Val: 5.0410e-05\n",
      "[2/32] Data Only | Train Data Loss: 3.8161e-05 | Train Phys Loss: 0.00e+00 | Val: 5.2447e-05\n",
      "[3/32] Data Only | Train Data Loss: 3.2852e-05 | Train Phys Loss: 0.00e+00 | Val: 5.1533e-05\n",
      "[4/32] Data Only | Train Data Loss: 3.5041e-05 | Train Phys Loss: 0.00e+00 | Val: 3.1953e-05\n",
      "[5/32] Ramping (0%) | Train Data Loss: 3.4710e-05 | Train Phys Loss: 0.00e+00 | Val: 2.0823e-05\n",
      "[6/32] Ramping (10%) | Train Data Loss: 2.4238e-05 | Train Phys Loss: 6.76e-07 | Val: 1.6381e-05\n",
      "[7/32] Ramping (20%) | Train Data Loss: 3.5515e-05 | Train Phys Loss: 1.35e-06 | Val: 1.6305e-05\n",
      "[8/32] Ramping (30%) | Train Data Loss: 2.2332e-05 | Train Phys Loss: 2.00e-06 | Val: 2.1266e-05\n",
      "[9/32] Ramping (40%) | Train Data Loss: 2.6217e-05 | Train Phys Loss: 2.64e-06 | Val: 1.1851e-05\n",
      "[10/32] Ramping (50%) | Train Data Loss: 1.7581e-05 | Train Phys Loss: 3.28e-06 | Val: 8.0752e-05\n",
      "[11/32] Ramping (60%) | Train Data Loss: 2.5949e-05 | Train Phys Loss: 3.90e-06 | Val: 1.4244e-05\n",
      "[12/32] Ramping (70%) | Train Data Loss: 2.3111e-05 | Train Phys Loss: 4.51e-06 | Val: 5.0749e-05\n",
      "[13/32] Ramping (80%) | Train Data Loss: 1.4531e-05 | Train Phys Loss: 5.10e-06 | Val: 9.6318e-06\n",
      "[14/32] Ramping (90%) | Train Data Loss: 1.5845e-05 | Train Phys Loss: 5.68e-06 | Val: 2.5249e-05\n",
      "[15/32] Full Phys | Train Data Loss: 1.9711e-05 | Train Phys Loss: 6.26e-06 | Val: 4.2777e-05\n",
      "[16/32] Full Phys | Train Data Loss: 1.5268e-05 | Train Phys Loss: 6.22e-06 | Val: 1.5063e-05\n",
      "[17/32] Full Phys | Train Data Loss: 1.6548e-05 | Train Phys Loss: 6.20e-06 | Val: 1.6367e-05\n",
      "[18/32] Full Phys | Train Data Loss: 1.3742e-05 | Train Phys Loss: 6.19e-06 | Val: 9.3869e-06\n",
      "[19/32] Full Phys | Train Data Loss: 1.4289e-05 | Train Phys Loss: 6.17e-06 | Val: 1.0139e-05\n",
      "[20/32] Full Phys | Train Data Loss: 1.5121e-05 | Train Phys Loss: 6.16e-06 | Val: 1.0475e-05\n",
      "[21/32] Full Phys | Train Data Loss: 1.2491e-05 | Train Phys Loss: 6.14e-06 | Val: 1.2317e-05\n",
      "[22/32] Full Phys | Train Data Loss: 1.1820e-05 | Train Phys Loss: 6.13e-06 | Val: 5.9751e-06\n",
      "[23/32] Full Phys | Train Data Loss: 1.2136e-05 | Train Phys Loss: 6.12e-06 | Val: 1.0477e-05\n",
      "[24/32] Full Phys | Train Data Loss: 1.2468e-05 | Train Phys Loss: 6.11e-06 | Val: 1.5063e-05\n",
      "[25/32] Full Phys | Train Data Loss: 1.1818e-05 | Train Phys Loss: 6.10e-06 | Val: 6.3122e-06\n",
      "[26/32] Full Phys | Train Data Loss: 1.1145e-05 | Train Phys Loss: 6.09e-06 | Val: 2.1308e-05\n",
      "[27/32] Full Phys | Train Data Loss: 1.0976e-05 | Train Phys Loss: 6.09e-06 | Val: 2.7757e-05\n",
      "[28/32] Full Phys | Train Data Loss: 1.0360e-05 | Train Phys Loss: 6.07e-06 | Val: 6.7132e-06\n",
      "[29/32] Full Phys | Train Data Loss: 3.2423e-06 | Train Phys Loss: 6.06e-06 | Val: 2.9298e-06\n",
      "[30/32] Full Phys | Train Data Loss: 3.1100e-06 | Train Phys Loss: 6.06e-06 | Val: 2.8890e-06\n",
      "[31/32] Full Phys | Train Data Loss: 3.0773e-06 | Train Phys Loss: 6.06e-06 | Val: 2.8593e-06\n",
      "It takes 4991.24 s to train FNO2D\n"
     ]
    }
   ],
   "source": [
    "# --- HYPERPARAMETERS ---\n",
    "# ROLLOUT_STEPS must match the number of output steps provided by your DataLoader's y_batch.\n",
    "\n",
    "ROLLOUT_STEPS = 5  \n",
    "SAMPLING_PROB = 0.6\n",
    "EPOCHS =32\n",
    "NOISE_LEVEL =0.005\n",
    "PHYS_WEIGHT =1e-13\n",
    "\n",
    "result5 = train_and_test(scheduler5, model = model5,\n",
    "              phys_loss = phys_loss_fn5, data_loss = data_loss_fn5, optimizer = optimizer5,phys_weight = PHYS_WEIGHT, train_loader = train_loader_t10,\n",
    "              dev_loader = val_loader_t10, epochs = EPOCHS,device = device, noise_level = NOISE_LEVEL, rollout_steps =ROLLOUT_STEPS , sampling_prob =SAMPLING_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 5: {'train_data_loss': [0.003333898678821769, 5.907324953065989e-05, 3.816136999950303e-05, 3.285162012999583e-05, 3.504103225982123e-05, 3.470976001010154e-05, 2.423757678211826e-05, 3.551462441273064e-05, 2.233151404461272e-05, 2.621670441409438e-05, 1.7580840156274223e-05, 2.594936950883589e-05, 2.3111144668961827e-05, 1.4531499756757464e-05, 1.584483480703631e-05, 1.9711058236058115e-05, 1.5268003582222216e-05, 1.654756656199951e-05, 1.374202524091647e-05, 1.4289032811862661e-05, 1.5120776086309649e-05, 1.2490942741638527e-05, 1.1820120312940593e-05, 1.2136309433117276e-05, 1.2468175494799844e-05, 1.1817789914187558e-05, 1.1145375039727936e-05, 1.0975835014170643e-05, 1.0360224565183192e-05, 3.242282291466836e-06, 3.1099977023155878e-06, 3.0773104088822088e-06], 'train_phys_loss': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.757761424450391e-07, 1.347019388143125e-06, 2.0013928062882194e-06, 2.6439735391159934e-06, 3.2764086307093895e-06, 3.8976526809806645e-06, 4.509176935445644e-06, 5.09535226034859e-06, 5.682000007083923e-06, 6.257977796417207e-06, 6.217252906919006e-06, 6.201184105549094e-06, 6.1901544258831485e-06, 6.1670865152702316e-06, 6.1592130980834125e-06, 6.139152030989233e-06, 6.129425368001468e-06, 6.116978122341892e-06, 6.109367462165968e-06, 6.096312428748176e-06, 6.088683075854777e-06, 6.090677476991874e-06, 6.073172257912882e-06, 6.059680451448655e-06, 6.059790990183705e-06, 6.057483544467316e-06], 'val_data_loss': [0.00010168496152365823, 5.0410402210495114e-05, 5.2447187519409574e-05, 5.153309678501935e-05, 3.195312404821617e-05, 2.0823038065155625e-05, 1.6381012202422742e-05, 1.6304596141233798e-05, 2.1266083738579333e-05, 1.1851217342827232e-05, 8.075212890221535e-05, 1.4243993775934264e-05, 5.074914825736018e-05, 9.63175437826304e-06, 2.5248879706929944e-05, 4.277727535024852e-05, 1.5062724722393677e-05, 1.6366935122515198e-05, 9.38686513979084e-06, 1.0138769658110307e-05, 1.0475060029737348e-05, 1.2317314703187035e-05, 5.975081293123051e-06, 1.0476865436035238e-05, 1.5063229511724785e-05, 6.31220773752632e-06, 2.130847247905837e-05, 2.7757287487316795e-05, 6.7131550563119715e-06, 2.929799483522204e-06, 2.888952010330879e-06, 2.859340413677906e-06]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Result 5: {result5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szrIoqFiriPS",
    "outputId": "aec6d1c2-c7f4-4027-827f-aaa8492b9c24"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"Saving initial untrained models...\")\n",
    "\n",
    "# 1. Define a path to save your models in your Drive\n",
    "MODELS_PATH = Path(\"models\")\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "# 2. Define the save paths for each model\n",
    "MODEL5_SAVE_PATH = MODELS_PATH / \"model5_initial_state.pth\"\n",
    "\n",
    "\n",
    "# 3. Save the models' state dictionaries\n",
    "# .state_dict() saves only the learnable parameters (weights and biases)\n",
    "try:\n",
    "    torch.save(model5.state_dict(), MODEL5_SAVE_PATH)\n",
    "\n",
    "    print(f\"Successfully saved model4 to: {MODEL5_SAVE_PATH}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saving models: {e}\")\n",
    "\n",
    "# To load them back later (for inference or to resume training), you would:\n",
    "# 1. Re-create the model instance: model0 = FNO1D(WIDTH, K_MAX, x_grid_tensor).to(device)\n",
    "# 2. Load the weights: model0.load_state_dict(torch.load(MODEL0_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_autoregressive_rollout(model, file_paths, loss_fn, t_in, device, u_mean, u_std, v_mean, v_std):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        u_mean, u_std, etc.: Floats. MUST MATCH TRAINING STATS.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_rollout_loss = 0.0\n",
    "    valid_samples = 0\n",
    "    \n",
    "    print(f\"Starting Rollout Evaluation on {len(file_paths)} simulation files...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for case_path in tqdm(file_paths, desc=\"Evaluating Rollout\"):\n",
    "            \n",
    "            # 1. Load Raw Data\n",
    "            try:\n",
    "                u = np.load(os.path.join(case_path, 'u.npy')) \n",
    "                v = np.load(os.path.join(case_path, 'v.npy')) \n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "            # 2. Normalize using Training Stats\n",
    "            u_norm = (u - u_mean) / u_std\n",
    "            v_norm = (v - v_mean) / v_std\n",
    "\n",
    "            # Stack\n",
    "            vel = np.stack([u_norm, v_norm], axis=-1)\n",
    "            velocity_traj = torch.from_numpy(vel).float().to(device)\n",
    "\n",
    "            # Check length\n",
    "            total_time = velocity_traj.shape[0]\n",
    "            if total_time <= t_in: continue\n",
    "\n",
    "            # Prepare Input (First t_in steps)\n",
    "            initial_input = velocity_traj[:t_in] \n",
    "            current_window = initial_input.unsqueeze(0)\n",
    "            # Flatten batch & time for FNO input: (1, 64, 64, 20)\n",
    "            current_window = current_window.permute(0, 2, 3, 1,4).reshape(1, 64, 64, -1)\n",
    "\n",
    "            # Prepare Ground Truth (From t_in to End)\n",
    "            y_true_full = velocity_traj[t_in:] \n",
    "            \n",
    "            predictions = []\n",
    "            n_steps_to_predict = y_true_full.shape[0]\n",
    "            \n",
    "            # Autoregressive Loop\n",
    "            stable = True\n",
    "            for i in range(n_steps_to_predict):\n",
    "                y_next_pred = model(current_window) # Output: (1, 10, 64, 64, 2)\n",
    "                \n",
    "                if torch.any(torch.isinf(y_next_pred)) or torch.any(torch.isnan(y_next_pred)):\n",
    "                    print(f\"!!! Rollout unstable at step {i} !!!\")\n",
    "                    stable = False\n",
    "                    break\n",
    "                \n",
    "                predictions.append(y_next_pred)\n",
    "                \n",
    "                # Update Window: Shift left, append new prediction\n",
    "                # current_window: (1, 64, 64, 20)\n",
    "                # We want to drop the first 2 channels (oldest t) and append y_next_pred (newest t)\n",
    "                current_window = torch.cat((current_window[..., 2:], y_next_pred), dim=-1)\n",
    "\n",
    "            if not stable: continue\n",
    "\n",
    "            # Calculate Loss\n",
    "            # Stack predictions: (1, Time, 64, 64, 2)\n",
    "            y_pred_tensor = torch.stack(predictions, dim=1) \n",
    "            \n",
    "            # Reshape for MSE Loss (Batch * Time * Pixels * Channels)\n",
    "            loss = loss_fn(y_pred_tensor, y_true_full.unsqueeze(0))\n",
    "            total_rollout_loss += loss.item()\n",
    "            valid_samples += 1\n",
    "\n",
    "    if valid_samples == 0: return float('inf')\n",
    "    return total_rollout_loss / valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test...\n",
      "Starting Rollout Evaluation on 13 simulation files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a88642c71a24a86890f5ad184fb0635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Rollout:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results ---\n",
      "Model 5 (Autoregressive, 3-in) Test Loss: 1.6344\n"
     ]
    }
   ],
   "source": [
    "# (Run this in a new cell after training model2)\n",
    "\n",
    "print(\"Starting test...\")\n",
    "\n",
    "# Use test_loader_t1 (from cell 17) for a fair test\n",
    "# Use loss_fn0 (from cell 55) for a fair data-only loss\n",
    "\n",
    "rollout_loss_m5 = evaluate_autoregressive_rollout(\n",
    "    model=model5, \n",
    "    file_paths=test_files, \n",
    "    loss_fn=data_loss_fn5,           \n",
    "    device=device,\n",
    "    t_in=10,# <-- This correctly matches your model2\n",
    "    u_mean = u_mean,\n",
    "    v_mean = v_mean,\n",
    "    u_std = u_std,\n",
    "    v_std = v_std\n",
    ")\n",
    "\n",
    "print(\"\\n--- Test Results ---\")\n",
    "print(f\"Model 5 (Autoregressive, 3-in) Test Loss: {rollout_loss_m5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "ZgPw4e7GX44c",
    "outputId": "45db1610-5818-476e-f1d2-b39a03706b99"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pltW\n",
    "import numpy as np\n",
    "from results import result1, result0\n",
    "\n",
    "# --- IMPORTANT ---\n",
    "# You must copy the dictionary outputs from your notebook cells\n",
    "# (cell 50 for model0 and cell 67 for model1) and paste them here.\n",
    "# I have used your completed output from cell 50 as an example.\n",
    "# You will need to replace results_1 with your full 30-epoch output.\n",
    "\n",
    "# --- Create Epoch Array ---\n",
    "# Assumes both models were trained for the same number of epochs\n",
    "result0 = {'train_data_loss': [0.4110739827156067, 0.23925882577896118, 0.20458190143108368, 0.19567212462425232, 0.17208527028560638, 0.16243018209934235, 0.16161102056503296, 0.1497381031513214, 0.1424730122089386, 0.13952957093715668, 0.13167569041252136, 0.1314629167318344, 0.13347485661506653, 0.1252565085887909, 0.12282412499189377, 0.12299676984548569, 0.11490682512521744, 0.11774254590272903, 0.10972394794225693, 0.10895457118749619, 0.11255241930484772, 0.10872527211904526, 0.10500839352607727, 0.10531488806009293, 0.10197656601667404, 0.10225849598646164, 0.10453744977712631, 0.10029015690088272, 0.09715524315834045, 0.10300806164741516, 0.09627469629049301, 0.09561239928007126, 0.09352393448352814, 0.09420380741357803, 0.09108910709619522, 0.08958891034126282, 0.08952014893293381, 0.0945991724729538, 0.08834867179393768, 0.08973327279090881, 0.08752944320440292, 0.08816472440958023, 0.08264376223087311, 0.08628880232572556, 0.08571340143680573, 0.08524730801582336, 0.08302949368953705, 0.08613189309835434, 0.08262985199689865, 0.0860193744301796, 0.08372187614440918, 0.08175082504749298, 0.0784018486738205, 0.07959341257810593, 0.0778963565826416, 0.0784391239285469, 0.07724633812904358, 0.07945655286312103, 0.07577656954526901, 0.08160007745027542, 0.08002155274152756, 0.07753711193799973, 0.07859975844621658, 0.0764986202120781, 0.07406435161828995, 0.0723976269364357, 0.0739876925945282, 0.07461126893758774, 0.07415719330310822, 0.07250193506479263, 0.07158296555280685, 0.0725533589720726, 0.07088251411914825, 0.0713513195514679, 0.07630784064531326, 0.07213081419467926, 0.06057237461209297, 0.05909671634435654, 0.05885971337556839, 0.058606330305337906, 0.05847145989537239, 0.058534953743219376, 0.05826769769191742, 0.05820904299616814, 0.05816391482949257, 0.05802098661661148, 0.058009110391139984, 0.057899314910173416, 0.0577441044151783, 0.05807175859808922, 0.057901881635189056, 0.05766398832201958, 0.05750136449933052, 0.05765574425458908, 0.05767909809947014, 0.05718502774834633, 0.0571594312787056, 0.057440076023340225, 0.057252444326877594, 0.05690488591790199, 0.05690895393490791, 0.05691118910908699, 0.056899115443229675, 0.05672742426395416, 0.05663994699716568, 0.05657578259706497, 0.05658656731247902, 0.05656237527728081, 0.05650690570473671, 0.05641086399555206, 0.056626658886671066, 0.05617628991603851, 0.05610703304409981, 0.05624675750732422, 0.0564168281853199, 0.05596563592553139, 0.05595419928431511, 0.055922769010066986, 0.05574888736009598, 0.05567246302962303, 0.05585700646042824, 0.055710289627313614, 0.05597971752285957, 0.05580592527985573, 0.05584094300866127, 0.05574943125247955, 0.05546464025974274, 0.055211909115314484, 0.05526223033666611, 0.05522475764155388, 0.05564416944980621, 0.05541204661130905, 0.05530177429318428, 0.05499405786395073, 0.05497822165489197, 0.055076297372579575, 0.05496148020029068, 0.0547984354197979, 0.05514082685112953, 0.055032216012477875, 0.05497255548834801, 0.05481015145778656, 0.05463377758860588, 0.054746970534324646, 0.05454118177294731, 0.05435951054096222, 0.05476135388016701, 0.054547540843486786, 0.05460606887936592, 0.05433722585439682], 'train_phys_loss': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_data_loss': [0.2572142621354451, 0.21145666733620658, 0.19115776675088064, 0.1802690809681302, 0.17118003964424133, 0.15824853404173775, 0.17612133447139983, 0.14190959067098677, 0.13687605919345977, 0.1335370416442553, 0.13127026198402283, 0.1297357457261237, 0.12929621764591762, 0.12160444259643555, 0.15860963624621194, 0.12193896668770957, 0.13977357768823231, 0.11167937008634446, 0.11051414717757513, 0.11135667432395238, 0.11710662323804129, 0.10518188218748759, 0.10574372337451057, 0.11249114868659822, 0.10047837618797545, 0.10142433477772607, 0.09888798826270634, 0.09998914327413316, 0.10522396519543632, 0.10073239829332109, 0.09524016141418427, 0.09673324570296303, 0.0917700073785252, 0.09177173449406548, 0.09537116840245231, 0.0898829839295811, 0.09122747289282936, 0.09619156460440348, 0.09295563683623359, 0.09442581981420517, 0.0865695761546256, 0.08646621212126716, 0.08684119321997204, 0.089255215156646, 0.0872151656519799, 0.08562316390730086, 0.0906154742789647, 0.08481654382887341, 0.08532685396217164, 0.09498826461651969, 0.08751835993358068, 0.08428332919166201, 0.10068383375330577, 0.08187451710303624, 0.08577221821224879, 0.07869435054442239, 0.08390380430316167, 0.08048265462829954, 0.07998732867695037, 0.07940924309548877, 0.08420824247693258, 0.07788392381062584, 0.08739961293481645, 0.07972035036673622, 0.07721601213727679, 0.07708905519001068, 0.08067990259991752, 0.07722300066361351, 0.09537790822131294, 0.07313832954045325, 0.07719190785336116, 0.0766766376438595, 0.07478425805530851, 0.0733860337308475, 0.07394332036612526, 0.07324050420096942, 0.06501247840268272, 0.06459305080629531, 0.06465581023976916, 0.06449638975281564, 0.06492461772665145, 0.06398267458592143, 0.0644972435538731, 0.06389726597874884, 0.06378511274381289, 0.06382066389871022, 0.06389406625004042, 0.06369595667199483, 0.06350627009357725, 0.0635057757534678, 0.06327962041610763, 0.06329736746256313, 0.06380144559911319, 0.06318371796182223, 0.06303894472500635, 0.06305838967599565, 0.06306172854134015, 0.06316362587468964, 0.06280702772358107, 0.06297555837839369, 0.06427314351238901, 0.06272708405814474, 0.06253687392861124, 0.06268517643449799, 0.062455795646186855, 0.06254122944341765, 0.06238306195489944, 0.06241820912275996, 0.062523636493891, 0.06233104856477843, 0.0623762799752137, 0.06204700215704857, 0.06217261888678112, 0.06274812715867209, 0.0618926150694726, 0.06204395309563667, 0.06187254799500344, 0.061938941537860844, 0.06266835385135242, 0.06309285830883753, 0.06154843940148278, 0.06175081975876339, 0.06152673846199399, 0.06216449757653569, 0.06183923437954888, 0.06193630456451386, 0.06164784404256987, 0.06338022170322281, 0.06135745565333064, 0.06773435566869992, 0.06207913467808375, 0.0613168551926575, 0.061097964880958436, 0.06094158074212453, 0.06099840265417856, 0.06099581180347337, 0.06111503788639629, 0.06091841511310093, 0.06254472116392756, 0.06069481703970167, 0.060798205198749664, 0.0615965946917496, 0.060730867383499, 0.06066012004065135, 0.06074823173029082, 0.0605203460842844, 0.060685241033160496, 0.06406244617842492, 0.06041179910775215, 0.06047245848273474]}\n",
    "\n",
    "epochs = range(len(result0['train_data_loss']))\n",
    "\n",
    "\n",
    "# --- Create Plots ---\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Training Data Loss Comparison\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs, result0['train_data_loss'], label='Model 0 (Data Only)', color='blue')\n",
    "plt.plot(epochs, result1['train_data_loss'], label='Model 1 (PINO)', color='red')\n",
    "plt.title('Training Data Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Relative L2 Loss (L_data)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.yscale('log') # Use log scale if losses are very different\n",
    "\n",
    "# Plot 2: Validation Data Loss Comparison\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs, result0['val_data_loss'], label='Model 0 (Data Only)', color='blue')\n",
    "plt.plot(epochs, result1['val_data_loss'], label='Model 1 (PINO)', color='red')\n",
    "plt.title('Validation Data Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Relative L2 Loss (L_data)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Plot 3: Model 1 (PINO) Loss Breakdown\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs, result1['train_data_loss'], label='Data Loss', color='red')\n",
    "plt.plot(epochs, result1['train_phys_loss'], label='Physics Loss', color='green')\n",
    "plt.title('Model 1 (PINO) Loss Components')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.yscale('log') # Log scale is essential here since physics loss is large\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFaSyxwHvKRc"
   },
   "source": [
    "# I. Set ups for Data\n",
    "- Create data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xurTLQvkvTYW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4f1ebd5990>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "#device agnostic\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#Hyper Parameters\n",
    "RAND_SEED = 420\n",
    "torch.manual_seed(RAND_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLs_tsjKv3I2"
   },
   "source": [
    "## 1. Data Handling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd6yws-Av7Js"
   },
   "source": [
    "### 1.1 Set up for data handling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIjVX1DLwKFo",
    "outputId": "e898e1c5-62e8-44c6-b3bb-c76d99ba7442"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "#Data paths\n",
    "data_folder_path = Path(\"dataset\")\n",
    "data_path = data_folder_path / \"cfd_bench/cylinder_flow\"\n",
    "bc_path = data_path / \"bc\"\n",
    "geo_path = data_path / \"geo\"\n",
    "prop_path = data_path / \"prop\"\n",
    "\n",
    "CHANNELS =2 #(vx,vy)\n",
    "GRID_SIZE =64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Datasets classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BurgerDataset_Autoregressive_Sparse (FASTER dataset) defined.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Constants\n",
    "GRID_SIZE = 64\n",
    "CHANNELS = 2  # u, v\n",
    "\n",
    "class CylinderFlow_Autoregressive_Sparse(Dataset):\n",
    "    \"\"\"\n",
    "    Phase 2 Dataset for CFDBench Cylinder Flow.\n",
    "    - Loads u.npy and v.npy\n",
    "    - Input: Velocity History ONLY (Batch, 64, 64, 20)\n",
    "    - Output: Future Velocity (Batch, 64, 64, 10)\n",
    "    - Returns: x, y, params_map (Dictionary with Physics Metadata)\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, t_in=10, t_out=5, windows_per_sim=20):\n",
    "        self.t_in = t_in\n",
    "        self.t_out = t_out\n",
    "        self.total_steps = t_in + t_out \n",
    "        self.data_dir = data_dir \n",
    "        self.windows_per_sim = windows_per_sim\n",
    "        \n",
    "        # 1. Find valid case folders\n",
    "        self.file_paths = sorted([\n",
    "            os.path.join(data_dir, f) for f in os.listdir(data_dir) \n",
    "            if os.path.isdir(os.path.join(data_dir, f))\n",
    "        ])\n",
    "        \n",
    "        if not self.file_paths:\n",
    "            raise ValueError(f\"No case folders found in {data_dir}\")\n",
    "\n",
    "        # 2. Inspect first case for dimensions\n",
    "        first_case = self.file_paths[0]\n",
    "        self.ext = '.npy' if os.path.exists(os.path.join(first_case, 'u.npy')) else '.np'\n",
    "        \n",
    "        # Load shape\n",
    "        sample_u = np.load(os.path.join(first_case, f'u{self.ext}'), mmap_mode='r')\n",
    "        \n",
    "        self.num_timesteps = sample_u.shape[0]\n",
    "        self.max_start_time = self.num_timesteps - self.total_steps\n",
    "        \n",
    "        self.sims_in_dataset = len(self.file_paths)\n",
    "        self.length = self.sims_in_dataset * self.windows_per_sim\n",
    "        \n",
    "        print(f\"âœ… Dataset Ready: {self.length} samples. (Physics params separated)\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Identify Simulation\n",
    "        sim_idx = idx // self.windows_per_sim\n",
    "        case_path = self.file_paths[sim_idx]\n",
    "        json_path = os.path.join(case_path, \"params.json\")\n",
    "        \n",
    "        # 2. Random Start Time\n",
    "        start_time_index = np.random.randint(0, self.max_start_time + 1)\n",
    "        \n",
    "        # 3. Indices\n",
    "        end_in_index = start_time_index + self.t_in\n",
    "        end_out_index = end_in_index + self.t_out\n",
    "\n",
    "        # 4. Load Velocity Data\n",
    "        u_mmap = np.load(os.path.join(case_path, f'u{self.ext}'), mmap_mode='r')\n",
    "        v_mmap = np.load(os.path.join(case_path, f'v{self.ext}'), mmap_mode='r')\n",
    "        \n",
    "        # Slice\n",
    "        u_in = u_mmap[start_time_index : end_in_index]\n",
    "        v_in = v_mmap[start_time_index : end_in_index]\n",
    "        u_out = u_mmap[end_in_index : end_out_index]\n",
    "        v_out = v_mmap[end_in_index : end_out_index]\n",
    "        \n",
    "        # Stack\n",
    "        x_np = np.stack([u_in, v_in], axis=-1).copy()\n",
    "        y_np = np.stack([u_out, v_out], axis=-1).copy()\n",
    "        \n",
    "        # 5. Prepare Tensors\n",
    "        x_tensor = torch.from_numpy(x_np).permute(1, 2, 0, 3).reshape(GRID_SIZE, GRID_SIZE, -1)\n",
    "        y_tensor = torch.from_numpy(y_np).permute(1, 2, 0, 3).reshape(GRID_SIZE, GRID_SIZE, -1)\n",
    "        \n",
    "        # 6. Retrieve Physics Parameters\n",
    "        # Fallback for filename\n",
    "        if not os.path.exists(json_path):\n",
    "             json_path = os.path.join(case_path, \"case.json\")\n",
    "\n",
    "        # Default Map\n",
    "        params_map = {\"viscosity\": 0.001, \"density\": 1.0, \"x_max\": 0.16, \"x_min\": -0.06, \"y_max\": 0.06, \"y_min\": -0.06}\n",
    "\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                # Update defaults with real values\n",
    "                params_map.update(data)\n",
    "\n",
    "        return x_tensor.float(), y_tensor.float(), params_map\n",
    "\n",
    "print(\"âœ… CylinderFlow_Autoregressive_Sparse (Physics-Informed) defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bxCbENcSXxn"
   },
   "source": [
    "# II. Set up for model\n",
    "- Declare up model class\n",
    "- Set up loss functions\n",
    "- Train - test function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvlONEUK9rrM"
   },
   "source": [
    "## 1.Models set ups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJtxm1_c9pux"
   },
   "source": [
    "### 1.1 FNO2D layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rwCocGjBmd-",
    "outputId": "45f5b864-143d-41c6-a79a-c73ec5b572b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNO_Layer2D class defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class FNO_Layer2D(nn.Module):\n",
    "  \"\"\" A class act as one Fourier Layer as described in the original paper\"\"\"\n",
    "  def __init__(self,in_chanels, out_chanels,mode_x,mode_y):\n",
    "    super(FNO_Layer2D, self).__init__()\n",
    "    self.in_chanels = in_chanels\n",
    "    self.out_chanels = out_chanels\n",
    "    self.mode_x = mode_x\n",
    "    self.mode_y = mode_y\n",
    "    #Scaler to scale the parameters\n",
    "    self.scalar = (1/(in_chanels * out_chanels))\n",
    "    self.weight_x = nn.Parameter(\n",
    "        self.scalar * torch.rand(in_chanels,out_chanels,mode_x, mode_y, dtype = torch.cfloat)\n",
    "    )\n",
    "    self.weight_y = nn.Parameter(\n",
    "        self.scalar * torch.rand(in_chanels,out_chanels,mode_x, mode_y,dtype = torch.cfloat)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    #Size \n",
    "    batch,_,H,W = x.shape\n",
    "      \n",
    "    # FFT (2D fourier transform)\n",
    "    x_ft = torch.fft.rfft2(x)\n",
    "      \n",
    "    ## Fourier layer\n",
    "    out_ft = torch.zeros(\n",
    "        batch, self.out_chanels,H, W //2 +1,\n",
    "        dtype = torch.cfloat,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "    out_ft[:,:,:self.mode_x,:self.mode_y] = torch.einsum(\n",
    "        \"bixy,ioxy->boxy\",\n",
    "        x_ft[:,:,:self.mode_x,:self.mode_y],\n",
    "        self.weight_x\n",
    "    )\n",
    "\n",
    "    out_ft[:,:,-self.mode_x:,:self.mode_y] = torch.einsum(\n",
    "        \"bixy,ioxy->boxy\",\n",
    "        x_ft[:,:,-self.mode_x:, :self.mode_y],\n",
    "        self.weight_y\n",
    "    )\n",
    "    ## Inverse FFT\n",
    "    x = torch.fft.irfft2(out_ft , s=(H,W))\n",
    "    return x\n",
    "print(\"FNO_Layer2D class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQ8niYFl9tQW"
   },
   "source": [
    "### 1.2 FNO2D class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zrdAHRpJHZ9c",
    "outputId": "fd2c80f3-ef01-4e53-fa5c-34e95a783416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNO2D class defined.\n"
     ]
    }
   ],
   "source": [
    "class FNO2D(nn.Module):\n",
    "  def __init__(self ,width, mode_x, mode_y,in_chanels =1, out_chanels =200) :\n",
    "    \"\"\" Default is 1 time step -> 200 timestep rest\"\"\"\n",
    "    super(FNO2D,self).__init__()\n",
    "    self.in_chanels = in_chanels + 2 # add one more for the grid\n",
    "    self.out_chanels = out_chanels\n",
    "    self.width = width\n",
    "    self.mode_x = mode_x\n",
    "    self.mode_y = mode_y\n",
    "      \n",
    "    # P layer ( lift the input chanel up):\n",
    "    self.fc0 = nn.Linear(self.in_chanels, self.width)\n",
    "\n",
    "    # T block: 4 Fourier layers\n",
    "    self.conv0 = FNO_Layer2D(width,width,mode_x,mode_y)\n",
    "    self.w0 = nn.Conv2d(self.width,self.width,1)\n",
    "\n",
    "    self.conv1 = FNO_Layer2D(width,width,mode_x,mode_y)\n",
    "    self.w1 = nn.Conv2d(self.width,self.width,1)\n",
    "\n",
    "    self.conv2 = FNO_Layer2D(width,width,mode_x,mode_y)\n",
    "    self.w2 = nn.Conv2d(self.width,self.width,1)\n",
    "\n",
    "    self.conv3 = FNO_Layer2D(width,width,mode_x,mode_y)\n",
    "    self.w3 = nn.Conv2d(self.width,self.width,1)\n",
    "\n",
    "    # Q layer (project down to output_chanels)\n",
    "    self.fc1 = nn.Linear(width,width*2)\n",
    "    self.fc2 = nn.Linear(width*2, self.out_chanels)\n",
    "\n",
    "  def forward(self,x):\n",
    "    #Get the grid information\n",
    "    grid = get_grid(shape = x.shape)\n",
    "\n",
    "    # concat to the input\n",
    "    x = torch.cat((x,grid),dim=-1) # (batch,H,W,chanels)\n",
    "\n",
    "    ##Through P layer:\n",
    "    x = self.fc0(x)\n",
    "\n",
    "    x = x.permute(0,3,1,2) #(batch, chanel , H , W)\n",
    "\n",
    "    ##Through T\n",
    "    #1\n",
    "    x1 = self.conv0(x)\n",
    "    x2 = self.w0(x)\n",
    "    x = x1+x2\n",
    "    x = F.gelu(x)\n",
    "\n",
    "    #2\n",
    "    x1 = self.conv1(x)\n",
    "    x2 = self.w1(x)\n",
    "    x = x1+x2\n",
    "    x = F.gelu(x)\n",
    "\n",
    "    #3\n",
    "    x1 = self.conv2(x)\n",
    "    x2 = self.w2(x)\n",
    "    x = x1+x2\n",
    "    x = F.gelu(x)\n",
    "\n",
    "    #4\n",
    "    x1 = self.conv3(x)\n",
    "    x2 = self.w3(x)\n",
    "    x = x1+x2\n",
    "\n",
    "    #Switch back\n",
    "    x = x.permute(0, 2,3, 1) # (batch,H,W,chanels)\n",
    "\n",
    "    ## Through Q\n",
    "    x = self.fc1(x)\n",
    "    x = F.gelu(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "def get_grid(shape): \n",
    "    batch, H,W = shape[0], shape[1],shape[2]\n",
    "\n",
    "    grid_x = torch.tensor(np.linspace(-1,1,H), dtype= torch.float)\n",
    "    grid_y = torch.tensor(np.linspace(-1,1,W), dtype = torch.float)\n",
    "    \n",
    "    grid_x = grid_x.reshape(1, H, 1, 1).repeat([batch, 1, W, 1])\n",
    "    grid_y = grid_y.reshape(1, 1, W, 1).repeat([batch, H, 1, 1])\n",
    "    grid = torch.cat((grid_x, grid_y), dim =-1).to(device) \n",
    "    return grid \n",
    "\n",
    "print(\"FNO2D class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OESnYwx8-l3q"
   },
   "source": [
    "## 2.Loss functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 LPLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LpLoss(object):\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.size_average = size_average\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "        return diff_norms/y_norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Physic loss for NavierStoke2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hXTFStOJQYA_"
   },
   "outputs": [],
   "source": [
    "class NavierStoke2DLoss(nn.Module):\n",
    "    def __init__(self, dt=0.001, size_average=True):\n",
    "        super(NavierStoke2DLoss, self).__init__()\n",
    "        \n",
    "        self.dt = dt\n",
    "        self.data_loss_fn = LpLoss(size_average=size_average)\n",
    "        print(f\"ðŸ“‰ Loss Initialized\")\n",
    "\n",
    "    def compute_derivatives(self, u, v):\n",
    "        \"\"\"Vectorized derivatives for sequence (B, H, W, T)\"\"\"\n",
    "        # Reshape for 2D padding: (Batch*Time, 1, H, W)\n",
    "        b, h, w, t = u.shape\n",
    "        u_reshaped = u.permute(0, 3, 1, 2).reshape(b * t, 1, h, w)\n",
    "        v_reshaped = v.permute(0, 3, 1, 2).reshape(b * t, 1, h, w)\n",
    "\n",
    "        # Pad & Calculate Gradients\n",
    "        u_pad = F.pad(u_reshaped, (1, 1, 1, 1), mode='replicate')\n",
    "        v_pad = F.pad(v_reshaped, (1, 1, 1, 1), mode='replicate')\n",
    "\n",
    "        du_dx = (u_pad[..., 1:-1, 2:] - u_pad[..., 1:-1, :-2]) / (2 * self.dx)\n",
    "        du_dy = (u_pad[..., 2:, 1:-1] - u_pad[..., :-2, 1:-1]) / (2 * self.dy)\n",
    "        dv_dx = (v_pad[..., 1:-1, 2:] - v_pad[..., 1:-1, :-2]) / (2 * self.dx)\n",
    "        dv_dy = (v_pad[..., 2:, 1:-1] - v_pad[..., :-2, 1:-1]) / (2 * self.dy)\n",
    "\n",
    "        # Reshape back to (B, H, W, T)\n",
    "        return (\n",
    "            du_dx.view(b, t, h, w).permute(0, 2, 3, 1),\n",
    "            dv_dx.view(b, t, h, w).permute(0, 2, 3, 1),\n",
    "            du_dy.view(b, t, h, w).permute(0, 2, 3, 1),\n",
    "            dv_dy.view(b, t, h, w).permute(0, 2, 3, 1)\n",
    "        )\n",
    "\n",
    "    def laplacian(self, w):\n",
    "        b, h, w_dim, t = w.shape\n",
    "        w_reshaped = w.permute(0, 3, 1, 2).reshape(b * t, 1, h, w_dim)\n",
    "        w_pad = F.pad(w_reshaped, (1, 1, 1, 1), mode='replicate')\n",
    "        d2x = (w_pad[..., 1:-1, 2:] - 2 * w_pad[..., 1:-1, 1:-1] + w_pad[..., 1:-1, :-2]) / (self.dx ** 2)\n",
    "        d2y = (w_pad[..., 2:, 1:-1] - 2 * w_pad[..., 1:-1, 1:-1] + w_pad[..., :-2, 1:-1]) / (self.dy ** 2)\n",
    "        return (d2x + d2y).view(b, t, h, w_dim).permute(0, 2, 3, 1)\n",
    "\n",
    "    def cal_physics_loss(self, u, v, phys_params):\n",
    "        \"\"\"\n",
    "        u, v shape: (B, H, W, T_total)\n",
    "        \"\"\"\n",
    "        # 1. Get Viscosity (Batch, 1, 1, 1)\n",
    "        self.nu = self.nu.view(-1, 1, 1, 1)\n",
    "\n",
    "        # 2. Compute Derivatives\n",
    "        du_dx, dv_dx, du_dy, dv_dy = self.compute_derivatives(u, v)\n",
    "\n",
    "        # --- Continuity Loss ---\n",
    "        loss_con = torch.mean((du_dx + dv_dy) ** 2)\n",
    "\n",
    "        # --- Vorticity Loss ---\n",
    "        omega = dv_dx - du_dy\n",
    "        \n",
    "        # Time Derivative (Central Difference)\n",
    "        # Uses t-1 and t+1 to calculate slope at t. \n",
    "        # We lose first and last frame of the sequence.\n",
    "        omega_next = omega[..., 2:]\n",
    "        omega_prev = omega[..., :-2]\n",
    "        dw_dt = (omega_next - omega_prev) / (2 * self.dt)\n",
    "        \n",
    "        # Align Spatial Terms (Slice to center)\n",
    "        u_center = u[..., 1:-1]\n",
    "        v_center = v[..., 1:-1]\n",
    "        omega_center = omega[..., 1:-1]\n",
    "        \n",
    "        # Advection terms (u * grad(w))\n",
    "        dw_dx, _, dw_dy, _ = self.compute_derivatives(omega_center, torch.zeros_like(omega_center))\n",
    "        advection = u_center * dw_dx + v_center * dw_dy\n",
    "        \n",
    "        # Diffusion term\n",
    "        diffusion = self.nu * self.laplacian(omega_center)\n",
    "        \n",
    "        # Residual\n",
    "        residual = dw_dt + advection - diffusion\n",
    "        loss_vort = torch.mean(residual ** 2)\n",
    "\n",
    "        return loss_vort, loss_con\n",
    "\n",
    "    def forward(self, x_in, y_pred, y_true, phys_params):\n",
    "        \"\"\"\n",
    "        x_in: (Batch, H, W, 20 ) -> Contains History\n",
    "        y_pred: (Batch, H, W, T_out*2) -> Contains Predictions\n",
    "        \"\"\"\n",
    "        # 1. Setup Grid (Physical Units)\n",
    "        x_range = params_map.get(\"x_max\", 1.0) - params_map.get(\"x_min\", 0.0)\n",
    "        y_range = params_map.get(\"y_max\", 1.0) - params_map.get(\"y_min\", 0.0)\n",
    "        self.nu = params_map.get(\"viscosity\", 0.001)\n",
    "        \n",
    "        self.dx = x_range / 64.0\n",
    "        self.dy = y_range / 64.0\n",
    "\n",
    "        # 2. Data Loss\n",
    "        data_loss = self.data_loss_fn(y_pred, y_true)\n",
    "\n",
    "        # 3. Stitch History + Prediction for Physics\n",
    "        \n",
    "        # Assuming 2 physics params at the end:\n",
    "        vel_traj = torch.cat((x_in,y_pred), dim=-1) #(B,H,W,(T+10)*2)\n",
    "        \n",
    "        # Unpack Prediction (Interleaved u, v)\n",
    "        b, h, w, c = vel_traj.shape\n",
    "        t_steps = c // 2\n",
    "        vel_traj = vel_traj.view(b, h, w, t_steps, 2)\n",
    "        u_full = vel_traj[..., 0]\n",
    "        v_full = vel_traj[..., 1]\n",
    "        \n",
    "\n",
    "        # 4. Calculate Physics\n",
    "        loss_vort, loss_con = self.cal_physics_loss(u_full, v_full, phys_params)\n",
    "\n",
    "        return data_loss, loss_vort, loss_con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Loss function for autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLossOnly(nn.Module):\n",
    "    def __init__(self,size_average = True):\n",
    "        super(DataLossOnly,self).__init__()\n",
    "        self.size_average = size_average \n",
    "        self.data_loss_fn = LpLoss(size_average)\n",
    "    def forward(self,x_current,y_pred,y_target): \n",
    "        data_loss = self.data_loss_fn(y_pred,y_target) \n",
    "\n",
    "        return data_loss, torch.tensor(0.0).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwrbOb0Im6_N"
   },
   "source": [
    "## 3 Training & Evaluating process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVCqCrmtnB6c"
   },
   "source": [
    "### 3.1 Training and testing loops + printing time method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UiPrn5AiItIY"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, data_loader, phys_weight, loss_fn, optimizer, device, noise_level, rollout_steps, sampling_prob):\n",
    "    model.train()\n",
    "    total_data_loss = 0.0\n",
    "    total_phys_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Weights for the two physics components\n",
    "    W_VORT = 1.0\n",
    "    W_CONT = 1.0\n",
    "    CHANNELS = 2\n",
    "\n",
    "    for batch, (x, y, phys_params) in enumerate(data_loader):\n",
    "        x, y, phys_params = x.to(device), y.to(device), phys_params.to(device)\n",
    "        \n",
    "        if noise_level > 0.0:\n",
    "            x += torch.randn_like(x) * x.std() * noise_level\n",
    "            \n",
    "        x_current = x\n",
    "        loss_accumulated = 0.0\n",
    "        \n",
    "        # --- ROLLOUT LOOP ---\n",
    "        for step in range(rollout_steps):\n",
    "            \n",
    "            # 1. Forward Pass\n",
    "            y_pred = model(x_current) # (B, H, W, 2)\n",
    "            \n",
    "            # 2. Prepare Target\n",
    "            start_c = step * CHANNELS\n",
    "            end_c = (step + 1) * CHANNELS\n",
    "            y_target = y[..., start_c:end_c]\n",
    "            \n",
    "            \n",
    "            # 4. Calculate Loss\n",
    "            data_l, vort_l, con_l = loss_fn(x_current,y_pred, y_target, phys_params)\n",
    "            \n",
    "            # Accumulate\n",
    "            step_loss = data_l + phys_weight * (W_VORT * vort_l + W_CONT * con_l)\n",
    "            loss_accumulated += step_loss\n",
    "            \n",
    "            # 5. Update Window (Autoregressive)\n",
    "            if torch.rand(1) < sampling_prob:\n",
    "                next_in = y_target # Teacher Forcing\n",
    "            else:\n",
    "                next_in = y_pred   # Autoregressive\n",
    "                \n",
    "            # Slide window: Drop first 2 \n",
    "            x_current = torch.cat([\n",
    "                x_current[..., CHANNELS:], \n",
    "                next_in], dim=-1)\n",
    "\n",
    "            #Loss for report\n",
    "            total_data_loss += data_l.item() # Log last step for simplicity\n",
    "            total_phys_loss += (vort_l.item() + con_l.item())\n",
    "            total_samples += 1\n",
    "\n",
    "        # --- Backward Pass ---\n",
    "        # We backpropagate the SUM of losses from all steps\n",
    "        optimizer.zero_grad()\n",
    "        loss_accumulated.backward()\n",
    "        \n",
    "        # Clip gradients to prevent explosion during physics calculation\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    return total_data_loss / total_samples, total_phys_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aMb5BiS5qdhL"
   },
   "outputs": [],
   "source": [
    "#Testing loop\n",
    "def testing_loop(model:torch.nn.Module,\n",
    "                 data_loader: torch.utils.data.DataLoader,\n",
    "                 loss_fn:torch.nn.Module,\n",
    "                 device):\n",
    "\n",
    "  model.eval()\n",
    "  val_data_loss = 0\n",
    "  with torch.inference_mode(): # Disable gradient calculation\n",
    "    for batch,(x_batch, y_batch,phys_params) in enumerate(data_loader):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        # We only care about the data loss for validation\n",
    "        data_loss, _ ,_= loss_fn(x_batch, y_pred, y_batch[:,:,:,0:2],phys_params) #First step\n",
    "\n",
    "        #Accumulating\n",
    "        val_data_loss += data_loss.item()\n",
    "\n",
    "\n",
    "  #Scaling\n",
    "  val_data_loss /= len(data_loader)\n",
    "\n",
    "  return val_data_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TxQddBbytHSx"
   },
   "outputs": [],
   "source": [
    "def printing_time(start, end, model_name):\n",
    "    print(f\"It takes {(end-start):.2f} s to train {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dy8_8IFhyX8A"
   },
   "source": [
    "### 3.2 Traing & validating for epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nZ1R_mhfs4_1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def train_and_test(lr_scheduler, model: torch.nn.Module,\n",
    "                   loss_fn:torch.nn.Module, optimizer: torch.optim.Optimizer,phys_weight :float, train_loader,\n",
    "                   dev_loader, epochs = 100, device = device,noise_level =0.0, rollout_steps =5, sampling_prob =0.9):\n",
    "  #Setups\n",
    "  model.to(device)\n",
    "\n",
    "  results = {\n",
    "      \"train_data_loss\":[],\n",
    "      \"train_phys_loss\":[],\n",
    "      \"val_data_loss\":[],\n",
    "  }\n",
    "\n",
    "  #Start timing\n",
    "  start_time = timer()\n",
    "\n",
    "  #Start\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    if epoch %8 == 0:\n",
    "      print(\"--------------------------\")\n",
    "      print(f\"Epoch: {epoch}\\n--------------\")\n",
    "        \n",
    "      sampling_prob -=0.1\n",
    "\n",
    "    #Training\n",
    "    train_data_loss, train_phys_loss = training_loop(model,train_loader, phys_weight, loss_fn, optimizer,device,noise_level,rollout_steps,sampling_prob)\n",
    "\n",
    "    #Testing\n",
    "    val_data_loss = testing_loop(model,dev_loader,loss_fn,device)\n",
    "\n",
    "    #Decay lr based on val_loss\n",
    "    lr_scheduler.step(val_data_loss)\n",
    "\n",
    "    #Printing\n",
    "    if epoch % 8 ==0:\n",
    "      print(f\"Train data Loss:{train_data_loss:.3f} || Train physic Loss:{train_phys_loss:.3f} || Test Loss:{val_data_loss:.3f}\")\n",
    "\n",
    "    #Restore values\n",
    "    results[\"train_data_loss\"].append(train_data_loss.item() if isinstance(train_data_loss, torch.Tensor) else train_data_loss)\n",
    "    results[\"train_phys_loss\"].append(train_phys_loss.item() if isinstance(train_phys_loss, torch.Tensor) else train_phys_loss)\n",
    "    results[\"val_data_loss\"].append(val_data_loss.item() if isinstance(val_data_loss, torch.Tensor) else val_data_loss)\n",
    "\n",
    "  #Printing time\n",
    "  print(\"--------------------------\")\n",
    "  end_time = timer()\n",
    "  printing_time(start_time,end_time,type(model).__name__)\n",
    "\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr18PLMh4_QT"
   },
   "source": [
    "### 3.3 Evaluating model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTXuX_L7-HcG"
   },
   "source": [
    "# III. Models 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vigQePZJFIG"
   },
   "source": [
    "## 1.DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 T10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples (windows): 20000\n",
      "Total dev samples (windows): 5000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from numpy import random\n",
    "\n",
    "#Attributes of the data set\n",
    "T_in = 10\n",
    "T_out = 5\n",
    "BATCH_SIZE = 32\n",
    "WINDOW_PER_SIM_TRAIN = 20 # 20 random windows per sim\n",
    "WINDOW_PER_SIM_DEV = 50  \n",
    "\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Set seed for reproducibility so test set stays same\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "print(f\"âœ… Dataset Split:\")\n",
    "print(f\"   Train: {len(train_ds)} samples\")\n",
    "print(f\"   Val:   {len(val_ds)} samples\")\n",
    "print(f\"   Test:  {len(test_ds)} samples\")\n",
    "\n",
    "# 3. Create DataLoaders\n",
    "# Use num_workers=0 for safety, or 2-4 if on Linux/Mac\n",
    "train_loader_t10 = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader_t10 = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader_t10 = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"ðŸŽ‰ DataLoaders are ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iEmNvrMskFm"
   },
   "source": [
    "## 4. Model 4\n",
    "**(Plautaue at .. epoch after .. hour)\n",
    "\n",
    "** Model 4 (Autoregressive, 3-in) Test Loss: \n",
    "\n",
    "- use data_t10 \n",
    "- FNO2D\n",
    "- DatalossOnly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPER Parameters from the paper\n",
    "WIDTH =64\n",
    "T_IN =10\n",
    "T_OUT =1\n",
    "MODE_X = 12\n",
    "MODE_Y = 12\n",
    "\n",
    "#Define model\n",
    "model5 = FNO2D(in_chanels=T_IN*CHANNELS, \n",
    "                 out_chanels=T_OUT*CHANNELS, \n",
    "                 mode_x=MODE_X, \n",
    "                 mode_y=MODE_Y, \n",
    "                 width=WIDTH).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt =0.001 #(Please modify if doesnt match)\n",
    "loss_fn5 = NavierStoke2DLoss(dt = dt, size_average =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "#Optimizer (Adam)\n",
    "LR =0.001\n",
    "optimizer5 = torch.optim.Adam(model4.parameters(),lr = LR)\n",
    "\n",
    "# We'll use 'ReduceLROnPlateau'.\n",
    "# This scheduler will automatically \"reduce\" the learning rate\n",
    "# when it detects that our validation loss has \"plateaued\" (stopped improving).\n",
    "scheduler5 = ReduceLROnPlateau(\n",
    "    optimizer4,\n",
    "    mode='min',      # It will look at the validation loss, where 'min' is better\n",
    "    factor=0.1,      # Reduce LR by a factor of 10 (e.g., 0.001 -> 0.0001)\n",
    "    patience=5,      # Wait 5 epochs for improvement before reducing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training and testing model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e51ad9d8fe84407a8fbcfe94d275fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Epoch: 0\n",
      "--------------\n",
      "Train data Loss:0.056 || Train physic Loss:0.000 || Test Loss:0.028\n",
      "--------------------------\n",
      "Epoch: 8\n",
      "--------------\n",
      "Train data Loss:0.014 || Train physic Loss:0.000 || Test Loss:0.009\n",
      "--------------------------\n",
      "It takes 3783.50 s to train FNO2D\n"
     ]
    }
   ],
   "source": [
    "# --- HYPERPARAMETERS ---\n",
    "# ROLLOUT_STEPS must match the number of output steps provided by your DataLoader's y_batch.\n",
    "\n",
    "ROLLOUT_STEPS = 5  \n",
    "SAMPLING_PROB = 0.9 \n",
    "EPOCHS =16\n",
    "NOISE_LEVEL =0.05\n",
    "PHYS_WEIGHT =0.001\n",
    "\n",
    "result5 = train_and_test(scheduler5, model = model5,\n",
    "              loss_fn = loss_fn5, optimizer = optimizer5,phys_weight = PHYS_WEIGHT, train_loader = train_loader_t10,\n",
    "              dev_loader = dev_loader_t10, epochs = EPOCHS,device = device, noise_level = NOISE_LEVEL, rollout_steps =ROLLOUT_STEPS , sampling_prob =SAMPLING_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 4: {'train_data_loss': [0.05087211075901985, 0.019582114146053792, 0.01718435420244932, 0.01622707962244749, 0.013885308791100979, 0.012675398913770914, 0.014305818380713462, 0.01390168257534504, 0.013852717347741126, 0.010688792301565409, 0.003958933025971055, 0.003676559438854456, 0.0035291603688895703, 0.0034527564647048713, 0.0033684210056811573, 0.003355002436041832], 'train_phys_loss': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_data_loss': [0.014770651550572009, 0.011961442513308327, 0.01349966850274118, 0.008752051269291503, 0.02810782082616144, 0.013955968230440739, 0.02735861696919818, 0.013814288179633344, 0.01048888521755387, 0.009351865329133098, 0.003875018720319317, 0.0037171958306519565, 0.0036459622057866616, 0.0034536947466575416, 0.0033496209067310307, 0.003377579756164152]}\n"
     ]
    }
   ],
   "source": [
    "    print(f\"Result 5: {result5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szrIoqFiriPS",
    "outputId": "aec6d1c2-c7f4-4027-827f-aaa8492b9c24"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"Saving initial untrained models...\")\n",
    "\n",
    "# 1. Define a path to save your models in your Drive\n",
    "MODELS_PATH = Path(\"models\")\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "# 2. Define the save paths for each model\n",
    "MODEL4_SAVE_PATH = MODELS_PATH / \"model4_initial_state.pth\"\n",
    "\n",
    "\n",
    "# 3. Save the models' state dictionaries\n",
    "# .state_dict() saves only the learnable parameters (weights and biases)\n",
    "try:\n",
    "    torch.save(model4.state_dict(), MODEL4_SAVE_PATH)\n",
    "\n",
    "    print(f\"Successfully saved model4 to: {MODEL4_SAVE_PATH}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error saving models: {e}\")\n",
    "\n",
    "# To load them back later (for inference or to resume training), you would:\n",
    "# 1. Re-create the model instance: model0 = FNO1D(WIDTH, K_MAX, x_grid_tensor).to(device)\n",
    "# 2. Load the weights: model0.load_state_dict(torch.load(MODEL0_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_autoregressive_rollout (2D version) function defined.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# This must match your model and dataset\n",
    "GRID_SIZE = 64\n",
    "CHANNELS = 2 # vx, vy\n",
    "T_IN = 10    # 10 steps in\n",
    "\n",
    "def evaluate_autoregressive_rollout(model, dataset, loss_fn,t_in, device):\n",
    "    \"\"\"\n",
    "    Performs a full autoregressive rollout on the 2D grid dataset\n",
    "    by loading each sample file.\n",
    "    \n",
    "    Args:\n",
    "        model: Your trained 2D FNO model\n",
    "        dataset: The CylinderFlowGridDataset object (e.g., dev_dataset)\n",
    "        loss_fn: An instance of your 2D LpLoss (NOT DataLossOnly)\n",
    "        device: Your \"cuda\" or \"cpu\" device\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_rollout_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Loop through each sample file in the dataset\n",
    "        for i in tqdm(range(len(dataset)), desc=\"Evaluating Rollout\"):\n",
    "            \n",
    "            # 1. Load the full 600-step trajectory for one sample\n",
    "            data = torch.load(dataset.file_paths[i])\n",
    "            # Shape: (600, 64, 64, 2)\n",
    "            velocity_traj = data['velocity'].to(device).to(torch.float32)\n",
    "\n",
    "            # --- 2. Create the first input window ---\n",
    "            # Get t=0...9\n",
    "            x_window_t = velocity_traj[:t_in] # (10, 64, 64, 2)\n",
    "            \n",
    "            # Reshape to (1, 64, 64, 20) for the model\n",
    "            current_window = x_window_t.permute(1, 2, 0, 3) \n",
    "            current_window = current_window.reshape(GRID_SIZE, GRID_SIZE, t_in * CHANNELS)\n",
    "            current_window = current_window.unsqueeze(0) # Add batch dim\n",
    "\n",
    "            # --- 3. Create the ground truth for comparison ---\n",
    "            # Get t=10...599\n",
    "            y_true_all_steps = velocity_traj[t_in:] # (590, 64, 64, 2)\n",
    "            \n",
    "            # Reshape to (1, 64, 64, 1180)\n",
    "            y_true_rollout = y_true_all_steps.permute(1, 2, 0, 3)\n",
    "            y_true_rollout = y_true_rollout.reshape(GRID_SIZE, GRID_SIZE, -1)\n",
    "            y_true_rollout = y_true_rollout.unsqueeze(0)\n",
    "\n",
    "            \n",
    "            predictions = [] # List to store all 590 predictions\n",
    "            n_steps = y_true_all_steps.shape[0] # 590 steps\n",
    "            \n",
    "            # --- 4. Start the rollout loop ---\n",
    "            for _ in range(n_steps):\n",
    "                # model input: (1, 64, 64, 20)\n",
    "                # model output: (1, 64, 64, 2)\n",
    "                y_pred_step = model(current_window)\n",
    "                \n",
    "                if torch.any(torch.isinf(y_pred_step)) or torch.any(torch.isnan(y_pred_step)):\n",
    "                    print(f\"!!! Rollout became unstable at step {i} !!!\")\n",
    "                    break \n",
    "                \n",
    "                predictions.append(y_pred_step)\n",
    "                \n",
    "                # --- 5. Feed back in ---\n",
    "                # Drop oldest 2 channels, add new 2 channels\n",
    "                current_window = torch.cat(\n",
    "                    (current_window[:, :, :, CHANNELS:], y_pred_step), \n",
    "                    dim=3 # Concatenate on the channel dimension\n",
    "                )\n",
    "            \n",
    "            # --- 6. Stack all predictions ---\n",
    "            # y_pred_full_rollout shape: (1, 64, 64, 1180)\n",
    "            if len(predictions) != n_steps: # Handle unstable rollout\n",
    "                print(\"Rollout failed, skipping this sample.\")\n",
    "                continue\n",
    "                \n",
    "            y_pred_full_rollout = torch.cat(predictions, dim=3)\n",
    "            \n",
    "            # --- 7. Calculate final loss ---\n",
    "            # Use the simple LpLoss, not the DataLossOnly wrapper\n",
    "            rollout_loss = loss_fn(x_window_t,y_pred_full_rollout, y_true_rollout)\n",
    "            total_rollout_loss += rollout_loss[0]\n",
    "\n",
    "    # Return the average loss over all test samples\n",
    "    return total_rollout_loss / len(dataset.file_paths)\n",
    "\n",
    "print(\"evaluate_autoregressive_rollout (2D version) function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FAIR comparison rollout for Model 2 and 3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e889ce0fd640d6b61ec00210b0d8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Rollout:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fair Comparison Test Results ---\n",
      "Model 0 (Direct, Data-Only) Test Loss:     0.0617\n",
      "Model 1 (Direct, PINO, w=0.1) Test Loss:   0.063\n",
      "Model 4 (Autoregressive, 3-in) Test Loss: 0.3364\n"
     ]
    }
   ],
   "source": [
    "# (Run this in a new cell after training model2)\n",
    "\n",
    "print(\"Starting FAIR comparison rollout for Model 2 and 3...\")\n",
    "\n",
    "# Use test_loader_t1 (from cell 17) for a fair test\n",
    "# Use loss_fn0 (from cell 55) for a fair data-only loss\n",
    "\n",
    "rollout_loss_m4 = evaluate_autoregressive_rollout(\n",
    "    model=model4, \n",
    "    dataset=test_data_t10, \n",
    "    loss_fn=loss_fn4,           \n",
    "    device=device,\n",
    "    t_in=10# <-- This correctly matches your model2\n",
    ")\n",
    "\n",
    "print(\"\\n--- Fair Comparison Test Results ---\")\n",
    "print(f\"Model 0 (Direct, Data-Only) Test Loss:     0.0617\") # From cell 105\n",
    "print(f\"Model 1 (Direct, PINO, w=0.1) Test Loss:   0.063\") # From cell 111\n",
    "print(f\"Model 4 (Autoregressive, 3-in) Test Loss: {rollout_loss_m4:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "ZgPw4e7GX44c",
    "outputId": "45db1610-5818-476e-f1d2-b39a03706b99"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from results import result1, result0\n",
    "\n",
    "# --- IMPORTANT ---\n",
    "# You must copy the dictionary outputs from your notebook cells\n",
    "# (cell 50 for model0 and cell 67 for model1) and paste them here.\n",
    "# I have used your completed output from cell 50 as an example.\n",
    "# You will need to replace results_1 with your full 30-epoch output.\n",
    "\n",
    "# --- Create Epoch Array ---\n",
    "# Assumes both models were trained for the same number of epochs\n",
    "result0 = {'train_data_loss': [0.4110739827156067, 0.23925882577896118, 0.20458190143108368, 0.19567212462425232, 0.17208527028560638, 0.16243018209934235, 0.16161102056503296, 0.1497381031513214, 0.1424730122089386, 0.13952957093715668, 0.13167569041252136, 0.1314629167318344, 0.13347485661506653, 0.1252565085887909, 0.12282412499189377, 0.12299676984548569, 0.11490682512521744, 0.11774254590272903, 0.10972394794225693, 0.10895457118749619, 0.11255241930484772, 0.10872527211904526, 0.10500839352607727, 0.10531488806009293, 0.10197656601667404, 0.10225849598646164, 0.10453744977712631, 0.10029015690088272, 0.09715524315834045, 0.10300806164741516, 0.09627469629049301, 0.09561239928007126, 0.09352393448352814, 0.09420380741357803, 0.09108910709619522, 0.08958891034126282, 0.08952014893293381, 0.0945991724729538, 0.08834867179393768, 0.08973327279090881, 0.08752944320440292, 0.08816472440958023, 0.08264376223087311, 0.08628880232572556, 0.08571340143680573, 0.08524730801582336, 0.08302949368953705, 0.08613189309835434, 0.08262985199689865, 0.0860193744301796, 0.08372187614440918, 0.08175082504749298, 0.0784018486738205, 0.07959341257810593, 0.0778963565826416, 0.0784391239285469, 0.07724633812904358, 0.07945655286312103, 0.07577656954526901, 0.08160007745027542, 0.08002155274152756, 0.07753711193799973, 0.07859975844621658, 0.0764986202120781, 0.07406435161828995, 0.0723976269364357, 0.0739876925945282, 0.07461126893758774, 0.07415719330310822, 0.07250193506479263, 0.07158296555280685, 0.0725533589720726, 0.07088251411914825, 0.0713513195514679, 0.07630784064531326, 0.07213081419467926, 0.06057237461209297, 0.05909671634435654, 0.05885971337556839, 0.058606330305337906, 0.05847145989537239, 0.058534953743219376, 0.05826769769191742, 0.05820904299616814, 0.05816391482949257, 0.05802098661661148, 0.058009110391139984, 0.057899314910173416, 0.0577441044151783, 0.05807175859808922, 0.057901881635189056, 0.05766398832201958, 0.05750136449933052, 0.05765574425458908, 0.05767909809947014, 0.05718502774834633, 0.0571594312787056, 0.057440076023340225, 0.057252444326877594, 0.05690488591790199, 0.05690895393490791, 0.05691118910908699, 0.056899115443229675, 0.05672742426395416, 0.05663994699716568, 0.05657578259706497, 0.05658656731247902, 0.05656237527728081, 0.05650690570473671, 0.05641086399555206, 0.056626658886671066, 0.05617628991603851, 0.05610703304409981, 0.05624675750732422, 0.0564168281853199, 0.05596563592553139, 0.05595419928431511, 0.055922769010066986, 0.05574888736009598, 0.05567246302962303, 0.05585700646042824, 0.055710289627313614, 0.05597971752285957, 0.05580592527985573, 0.05584094300866127, 0.05574943125247955, 0.05546464025974274, 0.055211909115314484, 0.05526223033666611, 0.05522475764155388, 0.05564416944980621, 0.05541204661130905, 0.05530177429318428, 0.05499405786395073, 0.05497822165489197, 0.055076297372579575, 0.05496148020029068, 0.0547984354197979, 0.05514082685112953, 0.055032216012477875, 0.05497255548834801, 0.05481015145778656, 0.05463377758860588, 0.054746970534324646, 0.05454118177294731, 0.05435951054096222, 0.05476135388016701, 0.054547540843486786, 0.05460606887936592, 0.05433722585439682], 'train_phys_loss': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_data_loss': [0.2572142621354451, 0.21145666733620658, 0.19115776675088064, 0.1802690809681302, 0.17118003964424133, 0.15824853404173775, 0.17612133447139983, 0.14190959067098677, 0.13687605919345977, 0.1335370416442553, 0.13127026198402283, 0.1297357457261237, 0.12929621764591762, 0.12160444259643555, 0.15860963624621194, 0.12193896668770957, 0.13977357768823231, 0.11167937008634446, 0.11051414717757513, 0.11135667432395238, 0.11710662323804129, 0.10518188218748759, 0.10574372337451057, 0.11249114868659822, 0.10047837618797545, 0.10142433477772607, 0.09888798826270634, 0.09998914327413316, 0.10522396519543632, 0.10073239829332109, 0.09524016141418427, 0.09673324570296303, 0.0917700073785252, 0.09177173449406548, 0.09537116840245231, 0.0898829839295811, 0.09122747289282936, 0.09619156460440348, 0.09295563683623359, 0.09442581981420517, 0.0865695761546256, 0.08646621212126716, 0.08684119321997204, 0.089255215156646, 0.0872151656519799, 0.08562316390730086, 0.0906154742789647, 0.08481654382887341, 0.08532685396217164, 0.09498826461651969, 0.08751835993358068, 0.08428332919166201, 0.10068383375330577, 0.08187451710303624, 0.08577221821224879, 0.07869435054442239, 0.08390380430316167, 0.08048265462829954, 0.07998732867695037, 0.07940924309548877, 0.08420824247693258, 0.07788392381062584, 0.08739961293481645, 0.07972035036673622, 0.07721601213727679, 0.07708905519001068, 0.08067990259991752, 0.07722300066361351, 0.09537790822131294, 0.07313832954045325, 0.07719190785336116, 0.0766766376438595, 0.07478425805530851, 0.0733860337308475, 0.07394332036612526, 0.07324050420096942, 0.06501247840268272, 0.06459305080629531, 0.06465581023976916, 0.06449638975281564, 0.06492461772665145, 0.06398267458592143, 0.0644972435538731, 0.06389726597874884, 0.06378511274381289, 0.06382066389871022, 0.06389406625004042, 0.06369595667199483, 0.06350627009357725, 0.0635057757534678, 0.06327962041610763, 0.06329736746256313, 0.06380144559911319, 0.06318371796182223, 0.06303894472500635, 0.06305838967599565, 0.06306172854134015, 0.06316362587468964, 0.06280702772358107, 0.06297555837839369, 0.06427314351238901, 0.06272708405814474, 0.06253687392861124, 0.06268517643449799, 0.062455795646186855, 0.06254122944341765, 0.06238306195489944, 0.06241820912275996, 0.062523636493891, 0.06233104856477843, 0.0623762799752137, 0.06204700215704857, 0.06217261888678112, 0.06274812715867209, 0.0618926150694726, 0.06204395309563667, 0.06187254799500344, 0.061938941537860844, 0.06266835385135242, 0.06309285830883753, 0.06154843940148278, 0.06175081975876339, 0.06152673846199399, 0.06216449757653569, 0.06183923437954888, 0.06193630456451386, 0.06164784404256987, 0.06338022170322281, 0.06135745565333064, 0.06773435566869992, 0.06207913467808375, 0.0613168551926575, 0.061097964880958436, 0.06094158074212453, 0.06099840265417856, 0.06099581180347337, 0.06111503788639629, 0.06091841511310093, 0.06254472116392756, 0.06069481703970167, 0.060798205198749664, 0.0615965946917496, 0.060730867383499, 0.06066012004065135, 0.06074823173029082, 0.0605203460842844, 0.060685241033160496, 0.06406244617842492, 0.06041179910775215, 0.06047245848273474]}\n",
    "\n",
    "epochs = range(len(result0['train_data_loss']))\n",
    "\n",
    "\n",
    "# --- Create Plots ---\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Training Data Loss Comparison\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs, result0['train_data_loss'], label='Model 0 (Data Only)', color='blue')\n",
    "plt.plot(epochs, result1['train_data_loss'], label='Model 1 (PINO)', color='red')\n",
    "plt.title('Training Data Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Relative L2 Loss (L_data)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.yscale('log') # Use log scale if losses are very different\n",
    "\n",
    "# Plot 2: Validation Data Loss Comparison\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs, result0['val_data_loss'], label='Model 0 (Data Only)', color='blue')\n",
    "plt.plot(epochs, result1['val_data_loss'], label='Model 1 (PINO)', color='red')\n",
    "plt.title('Validation Data Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Relative L2 Loss (L_data)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Plot 3: Model 1 (PINO) Loss Breakdown\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs, result1['train_data_loss'], label='Data Loss', color='red')\n",
    "plt.plot(epochs, result1['train_phys_loss'], label='Physics Loss', color='green')\n",
    "plt.title('Model 1 (PINO) Loss Components')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.yscale('log') # Log scale is essential here since physics loss is large\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1a98920ebca0440a870a60a7600ef050": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f826a8c1e04462f9f2a3b14ba2c9c7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a47940e2300a41f9960234ae87cc9017",
      "max": 150,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8130aea889c94b018434b8640338c440",
      "value": 150
     }
    },
    "206ade5cd57243c59d1ae55cd5fb498e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cf95d50e8014c0bb6462432fc8f7bc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "48fe616a363746f5822fd7350557bcf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b9eb26f841b45a5a94f43f4e53a4cfb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5d11d96b53d14e8f8817cf18898e04c1",
      "value": "100%"
     }
    },
    "5403a181ccf54280a9529c6c2aa0d93b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e04cb363eb724b709b61735d95aef361",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a11267c6534149a5959835643a7b1374",
      "value": "100%"
     }
    },
    "54c4444c2e92457e99c685a22247e940": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48fe616a363746f5822fd7350557bcf7",
       "IPY_MODEL_1f826a8c1e04462f9f2a3b14ba2c9c7a",
       "IPY_MODEL_60e161d1266c468e9efa47f42834ee29"
      ],
      "layout": "IPY_MODEL_aeaaa8c959114f1489681efaf449461d"
     }
    },
    "55a1f2e4a9d24d7eb0b71a7aef6116fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb44859138d1400a8ff8ee5f5afc2f95",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ab1d2926c70b45d790e5c40e3cb0950d",
      "value": "â€‡150/150â€‡[29:45&lt;00:00,â€‡11.97s/it]"
     }
    },
    "5d11d96b53d14e8f8817cf18898e04c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60e161d1266c468e9efa47f42834ee29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_206ade5cd57243c59d1ae55cd5fb498e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1a98920ebca0440a870a60a7600ef050",
      "value": "â€‡150/150â€‡[29:39&lt;00:00,â€‡11.93s/it]"
     }
    },
    "6b9eb26f841b45a5a94f43f4e53a4cfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8130aea889c94b018434b8640338c440": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8743875a3c56434c94ee74b9bcb21a9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5403a181ccf54280a9529c6c2aa0d93b",
       "IPY_MODEL_89bc54136b924aafa9206a2fb788eb7b",
       "IPY_MODEL_55a1f2e4a9d24d7eb0b71a7aef6116fd"
      ],
      "layout": "IPY_MODEL_a6ac3e77e78d4df1b76738eb81ad0a8d"
     }
    },
    "89bc54136b924aafa9206a2fb788eb7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9403c207ea774b00ace3374512205df9",
      "max": 150,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3cf95d50e8014c0bb6462432fc8f7bc9",
      "value": 150
     }
    },
    "9403c207ea774b00ace3374512205df9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a11267c6534149a5959835643a7b1374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a47940e2300a41f9960234ae87cc9017": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6ac3e77e78d4df1b76738eb81ad0a8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab1d2926c70b45d790e5c40e3cb0950d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aeaaa8c959114f1489681efaf449461d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb44859138d1400a8ff8ee5f5afc2f95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e04cb363eb724b709b61735d95aef361": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
